WEBVTT

1
00:00:00.520 --> 00:00:01.600
各位同学大家下午好

2
00:00:01.600 --> 00:00:02.320
我叫王鹤

3
00:00:02.320 --> 00:00:03.080
来自美团

4
00:00:03.280 --> 00:00:05.800
今天下午给大家带来一个主题是

5
00:00:05.800 --> 00:00:07.080
美团前端日志系统

6
00:00:07.080 --> 00:00:08.440
Logan的最佳实践

7
00:00:09.280 --> 00:00:10.600
首先做个自我介绍

8
00:00:11.280 --> 00:00:13.320
我是2013年加入美团

9
00:00:13.600 --> 00:00:16.440
先后负责过我们美团的大项 前端

10
00:00:16.880 --> 00:00:18.480
以及基础架构团队等

11
00:00:18.480 --> 00:00:21.320
目前是在基础技术部的前端技术中心

12
00:00:21.320 --> 00:00:23.840
负责美团整个前端的

13
00:00:24.160 --> 00:00:25.360
研发工具 运维工具

14
00:00:25.360 --> 00:00:26.880
和一些中间件的建设工作

15
00:00:28.600 --> 00:00:30.120
今天给大家带来这个主题

16
00:00:30.360 --> 00:00:32.040
就是我们今天的一些目录

17
00:00:32.280 --> 00:00:33.600
首先跟大家介绍一下

18
00:00:33.600 --> 00:00:34.280
什么是Logan

19
00:00:34.840 --> 00:00:37.600
然后在整个建设过程中

20
00:00:37.600 --> 00:00:39.520
我们遇到哪些问题和挑战

21
00:00:39.640 --> 00:00:40.680
我们的解决方案是什么

22
00:00:41.880 --> 00:00:43.440
后面会给大家介绍一下

23
00:00:43.440 --> 00:00:46.320
我们在美团内部工作的场景当中

24
00:00:46.320 --> 00:00:47.720
是怎么用Logan

25
00:00:47.720 --> 00:00:49.680
解决日常工作的一些问题的

26
00:00:50.520 --> 00:00:52.040
最后跟大家分享一下

27
00:00:52.040 --> 00:00:54.200
在整个日志的建设过程当中

28
00:00:54.640 --> 00:00:56.520
我们有哪些最佳实践

29
00:00:56.560 --> 00:00:58.280
和演进的一些建议

30
00:00:59.160 --> 00:01:00.760
首先我们来看一下

31
00:01:01.240 --> 00:01:03.600
当我们没有日志的时候

32
00:01:03.880 --> 00:01:05.880
我们工程师是怎么去解决问题的

33
00:01:06.920 --> 00:01:09.360
可能是来自用户的直接反馈

34
00:01:09.480 --> 00:01:11.200
或者产品经理QA说

35
00:01:11.560 --> 00:01:12.880
我遇到什么问题了

36
00:01:13.640 --> 00:01:15.320
工程师该怎么去解决问题呢

37
00:01:15.840 --> 00:01:18.640
可能根据口述的描述去复现

38
00:01:18.640 --> 00:01:22.120
我们复现整个问题的还原的场景

39
00:01:23.280 --> 00:01:25.160
然后如果复现不出来

40
00:01:25.560 --> 00:01:27.360
可能还要去整个人工去走查

41
00:01:27.360 --> 00:01:28.720
我们整个代码逻辑

42
00:01:29.280 --> 00:01:30.600
这是比较原始的时代

43
00:01:32.040 --> 00:01:33.680
后期随着业务的发展

44
00:01:33.720 --> 00:01:36.240
我们有更多的日志系统上来之后

45
00:01:36.440 --> 00:01:37.320
可能各个业务

46
00:01:37.360 --> 00:01:38.720
每个业务有自己的这种

47
00:01:39.600 --> 00:01:40.560
日志的通道

48
00:01:41.760 --> 00:01:44.040
但是这也延伸一个问题

49
00:01:44.040 --> 00:01:45.400
就是每一个业务

50
00:01:45.400 --> 00:01:46.480
它们的日志的通道

51
00:01:46.600 --> 00:01:48.600
可能有自己的个性化

52
00:01:49.080 --> 00:01:49.480
个性化

53
00:01:50.120 --> 00:01:52.960
这是我们在Logan系统诞生之前

54
00:01:53.240 --> 00:01:54.800
我们面临的一些场景

55
00:01:55.320 --> 00:01:56.560
我们来总结看一下

56
00:01:56.560 --> 00:01:59.040
在Logan建设过程当中

57
00:01:59.080 --> 00:02:00.080
我们会遇到哪些问题

58
00:02:01.120 --> 00:02:02.720
首先说第一个问题

59
00:02:03.600 --> 00:02:06.440
我们如何能够低成本地去进行接入

60
00:02:06.640 --> 00:02:07.240
我们刚才提到

61
00:02:07.840 --> 00:02:09.720
我们有很多个业务线

62
00:02:10.000 --> 00:02:10.920
可能有100多个

63
00:02:10.920 --> 00:02:12.800
这样的一个业务团队

64
00:02:12.840 --> 00:02:16.280
那么大家该如何统一进行接入

65
00:02:16.280 --> 00:02:18.000
并且按照我们的规范

66
00:02:18.000 --> 00:02:19.600
去进行低成本的接入

67
00:02:20.560 --> 00:02:21.560
这是我们的挑战

68
00:02:22.800 --> 00:02:23.920
第二个就是说

69
00:02:23.960 --> 00:02:25.720
我们的流量非常的大

70
00:02:26.040 --> 00:02:28.240
所以可能本地产生的日志

71
00:02:28.400 --> 00:02:29.320
它的体积非常大

72
00:02:29.320 --> 00:02:30.880
我们该如何进行存储

73
00:02:31.560 --> 00:02:32.760
存储 上报 解析

74
00:02:33.080 --> 00:02:33.880
这是挑战二

75
00:02:34.920 --> 00:02:36.520
第三个就是我们整个

76
00:02:37.120 --> 00:02:38.200
日志的可读性

77
00:02:38.560 --> 00:02:40.320
其实这个是更偏向于

78
00:02:40.720 --> 00:02:42.640
我们整个工程师在日常中

79
00:02:42.640 --> 00:02:43.880
去分析问题的时候

80
00:02:44.360 --> 00:02:46.680
那么该怎么样提供他们的应用性

81
00:02:48.840 --> 00:02:51.400
第四个就是日志的孤岛问题

82
00:02:52.320 --> 00:02:54.840
我们讲在研发过程当中

83
00:02:54.840 --> 00:02:56.440
日志可能有很多类

84
00:02:56.440 --> 00:02:58.520
比如说网络

85
00:02:58.840 --> 00:03:00.680
上层可能很有容器类的

86
00:03:01.200 --> 00:03:03.000
再上层可能有一些应用类的

87
00:03:03.360 --> 00:03:05.760
我是从哪个页面跳转到哪个页面

88
00:03:05.840 --> 00:03:06.800
到底发生了什么

89
00:03:07.640 --> 00:03:08.840
这些一连串的

90
00:03:09.520 --> 00:03:13.560
看似是每一个是在技术上是鼓励的

91
00:03:13.600 --> 00:03:15.560
但是从用户的行为角度来讲

92
00:03:15.600 --> 00:03:17.600
它是一个完整的用户行为

93
00:03:18.160 --> 00:03:20.160
这些日志实际上

94
00:03:20.160 --> 00:03:22.640
如何把它们串联在一起

95
00:03:23.000 --> 00:03:26.200
形成反应用户真实行为的

96
00:03:26.560 --> 00:03:27.440
这样的一个在线

97
00:03:27.440 --> 00:03:28.400
就是一个挑战

98
00:03:29.480 --> 00:03:30.200
最后一个就是

99
00:03:30.200 --> 00:03:32.600
我们整个日志的安全性的问题

100
00:03:33.400 --> 00:03:34.720
以及系统的可用性问题

101
00:03:35.320 --> 00:03:36.160
这是我们在

102
00:03:36.640 --> 00:03:38.720
建设前端日志系统的

103
00:03:38.880 --> 00:03:40.080
主要面临的几个问题

104
00:03:42.160 --> 00:03:43.840
接下来就看一下Logan

105
00:03:44.440 --> 00:03:45.720
给大家介绍一下Logan

106
00:03:45.720 --> 00:03:47.520
美团前端的日志系统

107
00:03:48.080 --> 00:03:49.720
主要它这个诞生

108
00:03:49.840 --> 00:03:52.160
解决了刚才上面几个问题

109
00:03:53.000 --> 00:03:53.720
第一类就是

110
00:03:53.720 --> 00:03:55.960
我们要满足日志系统的一些基本的诉求

111
00:03:56.240 --> 00:03:57.160
包括刚才提到的

112
00:03:57.160 --> 00:03:58.960
我们有统一的接入方式

113
00:03:59.360 --> 00:04:00.480
统一的日志服务

114
00:04:00.920 --> 00:04:02.880
我们有统一的这样的一个日志的

115
00:04:02.880 --> 00:04:04.200
查询和分析平台

116
00:04:04.920 --> 00:04:08.480
第二点就是我们帮助业务去排查

117
00:04:08.520 --> 00:04:10.680
和进行问题的定位分析

118
00:04:10.680 --> 00:04:12.960
所以我们要去串联公司内

119
00:04:13.040 --> 00:04:16.160
多个这样日志的服务和监控系统

120
00:04:17.320 --> 00:04:18.200
最后一点就是

121
00:04:18.200 --> 00:04:19.840
在可用性和安全性上

122
00:04:19.840 --> 00:04:21.080
我们要做到一些保障

123
00:04:22.520 --> 00:04:25.080
这也是我今天要给大家

124
00:04:25.080 --> 00:04:27.560
接下来要详细去介绍的内容

125
00:04:29.520 --> 00:04:30.120
我们看一下

126
00:04:30.880 --> 00:04:33.400
在Logan的日志的架构和设计上

127
00:04:34.000 --> 00:04:36.760
我今天会挑几个重要的核心点

128
00:04:36.760 --> 00:04:37.760
来跟大家分享

129
00:04:38.160 --> 00:04:40.160
第一个是我们端上的采集和存储

130
00:04:40.320 --> 00:04:41.040
该如何设计

131
00:04:41.080 --> 00:04:44.320
第二是我们的日志的解析和持久化

132
00:04:45.000 --> 00:04:45.280
怎么去做

133
00:04:45.840 --> 00:04:48.360
第三个是我们的可视化的平台

134
00:04:48.480 --> 00:04:50.280
也就是说日志平时

135
00:04:50.680 --> 00:04:53.280
工程师去进行日志的分析定位的时候

136
00:04:53.560 --> 00:04:55.320
所用到这样一个分析平台

137
00:04:56.960 --> 00:04:59.680
第四点就是我们的日志的串联能力

138
00:04:59.760 --> 00:05:02.040
第五点是数据安全和可用性保障

139
00:05:03.440 --> 00:05:04.400
接下来看一下

140
00:05:04.400 --> 00:05:05.920
我们整个Logan的

141
00:05:06.600 --> 00:05:08.800
系统的整个全局的架构图

142
00:05:09.600 --> 00:05:10.720
在正常的架构图上

143
00:05:10.720 --> 00:05:11.640
我们有五点

144
00:05:11.800 --> 00:05:12.640
大家可以看到

145
00:05:12.960 --> 00:05:15.480
第一块就是我们整个端上的采集

146
00:05:15.480 --> 00:05:16.400
和本地存储

147
00:05:17.040 --> 00:05:19.200
第二块就是日志的解析和持久化

148
00:05:19.640 --> 00:05:22.920
在这里就已经是到了后端了

149
00:05:24.160 --> 00:05:25.480
日志的解析数据化之后

150
00:05:25.640 --> 00:05:27.480
会为其他的服务

151
00:05:27.480 --> 00:05:29.920
提供我们应用性的API接口

152
00:05:30.240 --> 00:05:31.720
这些API接口就给到了

153
00:05:31.720 --> 00:05:33.240
我们可视化的分析平台

154
00:05:33.240 --> 00:05:35.600
以及其他需要进行

155
00:05:36.000 --> 00:05:37.680
日志查询的这样的一个服务

156
00:05:38.040 --> 00:05:39.280
比如说我们要去做

157
00:05:39.280 --> 00:05:40.800
整个日志的串联能力

158
00:05:41.160 --> 00:05:42.040
这是到了第四点

159
00:05:42.760 --> 00:05:43.520
底下这一块

160
00:05:43.680 --> 00:05:45.240
是我们整个日志的安全

161
00:05:45.240 --> 00:05:46.120
和可能性的保障

162
00:05:46.680 --> 00:05:48.680
这是我们Logan系统的整体的

163
00:05:48.680 --> 00:05:49.800
这样一个架构设计

164
00:05:51.880 --> 00:05:53.920
接下来我会按照几个模块

165
00:05:54.120 --> 00:05:55.640
再详细给大家介绍一下

166
00:05:56.120 --> 00:05:57.680
第一块是比较重要的

167
00:05:58.000 --> 00:05:59.520
端上的采集和本地存储

168
00:06:00.040 --> 00:06:01.400
这里实际上

169
00:06:01.400 --> 00:06:04.080
端上其实就是我们整个用户端

170
00:06:04.400 --> 00:06:05.720
SDK这块的设计

171
00:06:05.720 --> 00:06:08.560
在这里就能够体现到

172
00:06:08.560 --> 00:06:10.640
我们该如何提供低成本的

173
00:06:10.640 --> 00:06:11.560
这样的接入能力

174
00:06:11.560 --> 00:06:13.640
以及日志的规范化

175
00:06:14.160 --> 00:06:16.320
以及它的这个流程

176
00:06:16.320 --> 00:06:17.040
应该是怎么样的

177
00:06:18.240 --> 00:06:19.760
从这个图上来看

178
00:06:19.760 --> 00:06:20.240
大家看

179
00:06:20.600 --> 00:06:21.960
最上层是业务层

180
00:06:22.280 --> 00:06:24.360
我们有众多个业务

181
00:06:24.960 --> 00:06:28.880
下面就是我们提供的三类SDK

182
00:06:28.880 --> 00:06:31.960
第一类是Logan的Native SDK

183
00:06:31.960 --> 00:06:33.440
第二类是Web SDK

184
00:06:33.440 --> 00:06:35.440
第三类是小程序 SDK

185
00:06:35.440 --> 00:06:38.280
这几类其实我们横向上

186
00:06:38.280 --> 00:06:39.440
还可以有一个分层

187
00:06:39.680 --> 00:06:40.840
最上层是接入层

188
00:06:41.280 --> 00:06:44.600
我们接入层提供面向不同技术栈的

189
00:06:44.800 --> 00:06:45.680
这样的SDK

190
00:06:45.680 --> 00:06:47.840
中间这层我们叫API层

191
00:06:48.000 --> 00:06:50.120
比如说大家可以看到这个图的左侧

192
00:06:50.560 --> 00:06:53.240
Native SDK这里

193
00:06:53.240 --> 00:06:56.800
Logan有一层Logan Native API

194
00:06:56.800 --> 00:06:59.480
无论你是RN Flutter

195
00:06:59.480 --> 00:07:00.920
还有Picasso

196
00:07:00.920 --> 00:07:03.080
Picasso是我们的动态化容器

197
00:07:03.480 --> 00:07:04.520
无论是哪些技术栈

198
00:07:04.560 --> 00:07:06.520
它在顶层调用的时候

199
00:07:06.560 --> 00:07:08.720
API是统一的

200
00:07:10.240 --> 00:07:11.920
再往下层就是我们的逻辑层

201
00:07:12.400 --> 00:07:15.120
逻辑层更偏向于是本地端上的

202
00:07:15.120 --> 00:07:17.360
我们整个日志的采集

203
00:07:17.760 --> 00:07:20.000
存储 解析然后加密

204
00:07:20.360 --> 00:07:21.320
然后以及压缩

205
00:07:22.080 --> 00:07:23.760
最后是上报整体的逻辑

206
00:07:24.360 --> 00:07:25.200
所以这一层

207
00:07:25.280 --> 00:07:26.920
是我们把它称为逻辑层

208
00:07:27.760 --> 00:07:28.640
经过逻辑层之后

209
00:07:28.760 --> 00:07:31.200
最后日志要落在本地

210
00:07:31.200 --> 00:07:32.880
就是端上的这种数据库

211
00:07:33.120 --> 00:07:34.360
所以我们有存储层

212
00:07:35.360 --> 00:07:36.160
在这里可以看到

213
00:07:36.160 --> 00:07:38.280
我们端上的采集和本地存储

214
00:07:38.280 --> 00:07:39.840
为什么采用这样的形式

215
00:07:39.840 --> 00:07:41.440
我们的日志

216
00:07:41.440 --> 00:07:43.040
不是采用全量上报的

217
00:07:43.280 --> 00:07:43.480
也就是说

218
00:07:43.880 --> 00:07:45.160
不是每一份数据

219
00:07:45.160 --> 00:07:46.840
全都上报到服务端

220
00:07:48.080 --> 00:07:50.320
因此我们会采用端上的

221
00:07:50.320 --> 00:07:51.200
这样一个存储

222
00:07:51.200 --> 00:07:51.800
这样

223
00:07:51.800 --> 00:07:53.200
当我们有需要的时候

224
00:07:53.200 --> 00:07:54.480
可以把对应的日志

225
00:07:55.000 --> 00:07:56.640
再回传到服务端

226
00:07:56.640 --> 00:07:59.160
帮助开发者去定位和分析问题

227
00:08:00.080 --> 00:08:02.280
这是我们整个这块的逻辑

228
00:08:02.400 --> 00:08:04.480
采集和本地存储

229
00:08:06.280 --> 00:08:07.520
接下来详细介绍一下

230
00:08:07.800 --> 00:08:09.760
在分层里面

231
00:08:09.760 --> 00:08:11.320
我们有一个日志的分片

232
00:08:11.400 --> 00:08:12.720
为什么有分片存储

233
00:08:13.160 --> 00:08:13.800
刚才提到了

234
00:08:13.800 --> 00:08:15.680
我们的日志是存在端上的

235
00:08:16.200 --> 00:08:17.320
存在端上

236
00:08:17.320 --> 00:08:18.880
有众多的业务线

237
00:08:19.000 --> 00:08:21.760
众多的业务线都会在日志系统上

238
00:08:21.760 --> 00:08:23.040
进行日志的记录

239
00:08:23.040 --> 00:08:24.680
这样我们日志量会比较大

240
00:08:27.200 --> 00:08:30.320
如果采用全部存在一起

241
00:08:30.560 --> 00:08:31.880
这样会有几个问题

242
00:08:32.080 --> 00:08:33.040
第一个就是说

243
00:08:33.240 --> 00:08:34.320
上报的成功率会低

244
00:08:34.600 --> 00:08:37.280
有可能日志的文件会比较大

245
00:08:37.880 --> 00:08:39.840
其次可能还要重复上报

246
00:08:40.960 --> 00:08:41.440
当然了

247
00:08:41.440 --> 00:08:43.840
由于日志文件量大

248
00:08:43.880 --> 00:08:45.120
那么就会带来一个

249
00:08:45.520 --> 00:08:47.560
引发的一个就是流量会消耗的大一些

250
00:08:50.120 --> 00:08:52.600
最后后端的存储的压力大

251
00:08:52.760 --> 00:08:54.200
如果是采用全量上报

252
00:08:55.240 --> 00:08:56.200
后端的存储压力大

253
00:08:56.640 --> 00:08:59.200
所以我们采用的是分片方案

254
00:08:59.520 --> 00:09:00.120
分片方案

255
00:09:00.120 --> 00:09:02.720
分片方案其实比较简单

256
00:09:02.960 --> 00:09:07.040
那就是在本地在端上本地的时候

257
00:09:07.040 --> 00:09:08.320
我们去打日志的时候

258
00:09:08.520 --> 00:09:11.280
会按照一片一片的进行着日志存储

259
00:09:11.760 --> 00:09:14.040
大家可以理解成我举个例子

260
00:09:14.080 --> 00:09:14.360
比如说

261
00:09:14.400 --> 00:09:17.240
我们的本地的日志的容量是10兆

262
00:09:18.240 --> 00:09:19.040
我们按分片

263
00:09:19.160 --> 00:09:20.520
可能每一片是一兆

264
00:09:20.520 --> 00:09:21.720
这样我们就可以分10份

265
00:09:22.200 --> 00:09:22.680
分10份

266
00:09:22.680 --> 00:09:24.120
正好我们再去上报的时候

267
00:09:24.200 --> 00:09:27.000
就可以按照一片一片地进行上报

268
00:09:27.920 --> 00:09:30.080
这样后端去接收的时候

269
00:09:30.720 --> 00:09:33.440
这个也可以再把分片的日志

270
00:09:33.440 --> 00:09:34.880
再给连接起来

271
00:09:35.480 --> 00:09:36.600
听起来有点像什么

272
00:09:36.600 --> 00:09:39.320
有点像断点续传

273
00:09:39.320 --> 00:09:40.440
文件的这种断点续传

274
00:09:40.440 --> 00:09:46.480
我们去给他做一些文件的这种分片

275
00:09:46.640 --> 00:09:48.120
然后在后端再组装起来

276
00:09:48.120 --> 00:09:49.440
形成一个完整的日志文件

277
00:09:49.840 --> 00:09:52.280
但是这里也有很多设计的细节

278
00:09:52.400 --> 00:09:53.880
比如说我们的分片

279
00:09:54.360 --> 00:09:57.080
虽然说我们限制说一片是两兆

280
00:09:57.080 --> 00:09:58.520
但是我们不是说到两兆了

281
00:09:58.520 --> 00:09:59.640
我们就给它截断了

282
00:10:00.120 --> 00:10:02.040
而是大于两兆之后

283
00:10:02.360 --> 00:10:03.840
然后要保障

284
00:10:04.240 --> 00:10:05.640
最后一条日志能记录进去

285
00:10:06.160 --> 00:10:06.560
这样

286
00:10:06.560 --> 00:10:08.240
每一个分片内的日志

287
00:10:08.400 --> 00:10:10.120
它是完整的

288
00:10:11.280 --> 00:10:13.760
所以这是我们的一些小的设计

289
00:10:14.000 --> 00:10:15.200
可以给大家分享一下

290
00:10:16.920 --> 00:10:19.200
这是日志分片的存储

291
00:10:19.360 --> 00:10:22.200
第二点就是我们再看一看分片存储

292
00:10:22.360 --> 00:10:25.560
它的整个的这种设计逻辑

293
00:10:25.840 --> 00:10:26.680
就像刚才提到的

294
00:10:26.680 --> 00:10:28.400
我们会有多个分片

295
00:10:28.480 --> 00:10:32.600
然后我们上传到服务器

296
00:10:32.600 --> 00:10:34.440
服务器再进行合并

297
00:10:34.840 --> 00:10:35.840
这是这样一个逻辑

298
00:10:35.920 --> 00:10:38.200
这是一个示意图

299
00:10:38.200 --> 00:10:38.680
对

300
00:10:39.960 --> 00:10:41.200
第三点给大家讲一下

301
00:10:41.440 --> 00:10:43.800
本地的这种日志的这种存储

302
00:10:43.800 --> 00:10:45.600
本地存储那是客户端的

303
00:10:45.840 --> 00:10:47.920
我们客户端在记日志的时候

304
00:10:47.920 --> 00:10:49.800
为了能够更快

305
00:10:49.800 --> 00:10:51.280
然后并且能保证

306
00:10:51.880 --> 00:10:53.200
日志能够记录的完整

307
00:10:53.200 --> 00:10:54.480
所以我们采用的是

308
00:10:54.720 --> 00:10:57.680
进行着内存和MMAP这样的形式

309
00:10:58.280 --> 00:11:00.000
这样能更大限度上

310
00:11:00.040 --> 00:11:01.960
能够提升整个日志的

311
00:11:02.000 --> 00:11:03.560
这样的一个记录的性能

312
00:11:03.960 --> 00:11:05.080
然后并且保证在

313
00:11:05.560 --> 00:11:08.480
一些异常和特殊情况下的日志的完整性

314
00:11:09.640 --> 00:11:10.840
这是设计

315
00:11:11.040 --> 00:11:11.880
大家可以看到

316
00:11:11.880 --> 00:11:13.000
我们右侧这个图

317
00:11:13.560 --> 00:11:16.120
从日志我们经过加密压缩之后

318
00:11:16.120 --> 00:11:19.000
然后就开始去写入虚拟内存

319
00:11:19.000 --> 00:11:20.840
然后通过MMAP的映射

320
00:11:20.840 --> 00:11:23.280
最终再到我们整个日志文件

321
00:11:23.680 --> 00:11:24.800
这是这样一个过程

322
00:11:26.680 --> 00:11:28.240
第二点我们来看一看

323
00:11:28.600 --> 00:11:30.240
日志的解析和持久化

324
00:11:31.000 --> 00:11:31.840
我们解决了

325
00:11:32.440 --> 00:11:34.360
解决了端上存储的问题

326
00:11:34.440 --> 00:11:36.560
端上采集和存储的问题之后

327
00:11:37.440 --> 00:11:38.080
到了后端

328
00:11:38.200 --> 00:11:41.320
我们就到了日志的解析和持久化这一部分

329
00:11:41.320 --> 00:11:43.160
日志上来之后

330
00:11:43.160 --> 00:11:45.280
我们肯定是有接口层

331
00:11:45.400 --> 00:11:47.720
最上层用于去接收

332
00:11:47.720 --> 00:11:49.800
整个前端采集的日志的

333
00:11:50.920 --> 00:11:51.680
当然最上层

334
00:11:51.840 --> 00:11:53.600
还有给其他的日志服务

335
00:11:53.600 --> 00:11:55.920
和后面我们讲可视化分析平台

336
00:11:55.920 --> 00:11:59.360
和其他系统去提供的这种日志的API

337
00:11:59.360 --> 00:12:03.680
当然这种API已经是我们经过解析和

338
00:12:03.680 --> 00:12:04.480
包装之后的

339
00:12:04.480 --> 00:12:05.280
这样的一个接口

340
00:12:06.480 --> 00:12:09.120
在整个Logan的服务器这一层

341
00:12:09.160 --> 00:12:11.080
除了上层是接口层

342
00:12:11.080 --> 00:12:12.480
那么底层的就是服务层

343
00:12:12.960 --> 00:12:14.880
这个服务层就会包含

344
00:12:14.880 --> 00:12:17.560
我们要去进行日志的这样的接收

345
00:12:17.800 --> 00:12:20.000
接收可能就会解压 解密

346
00:12:20.400 --> 00:12:23.560
然后再进行日志的一些分析

347
00:12:23.960 --> 00:12:25.520
再落到根据我们不同场景

348
00:12:25.520 --> 00:12:27.440
我们是放在文件存储

349
00:12:27.440 --> 00:12:30.800
然后以及DB中

350
00:12:30.800 --> 00:12:32.840
然后还有缓存或者是ES

351
00:12:32.840 --> 00:12:35.360
我们去进行搜索这些数据库

352
00:12:36.000 --> 00:12:37.840
然后上层提供这样的接口

353
00:12:37.840 --> 00:12:40.520
再供其他的这样一个服务器进行使用

354
00:12:41.280 --> 00:12:42.800
这是第二点

355
00:12:42.840 --> 00:12:44.720
我们日志的这样解析和持久化

356
00:12:46.400 --> 00:12:47.840
第三块给大家看一下

357
00:12:47.920 --> 00:12:50.520
到了我们开发者

358
00:12:50.520 --> 00:12:52.120
可能会经常常用的

359
00:12:52.360 --> 00:12:53.400
可视化的日志平台

360
00:12:54.360 --> 00:12:55.520
当没有日志平台的时候

361
00:12:55.520 --> 00:12:58.000
我们开发者非常常见的这种

362
00:13:00.000 --> 00:13:01.880
解决去定位问题的模式

363
00:13:02.800 --> 00:13:05.120
在我们整个命令行窗口

364
00:13:05.840 --> 00:13:07.520
去查日志文件

365
00:13:08.000 --> 00:13:08.720
查日志文件

366
00:13:08.720 --> 00:13:09.800
然后自己去进行

367
00:13:09.800 --> 00:13:12.760
在日志文件中去进行日志的定位

368
00:13:13.560 --> 00:13:15.040
这样可能

369
00:13:15.040 --> 00:13:16.920
你单问题 单文件

370
00:13:17.360 --> 00:13:19.000
可以去进行去定位

371
00:13:19.560 --> 00:13:21.280
当这个问题复杂度比较高的时候

372
00:13:21.320 --> 00:13:23.960
你需要去在多个日志文件

373
00:13:24.000 --> 00:13:25.080
进行串联的时候

374
00:13:25.280 --> 00:13:27.960
可能这个成本就比较高

375
00:13:28.200 --> 00:13:29.280
我相信很多同学

376
00:13:29.760 --> 00:13:31.240
都有这样的经历

377
00:13:31.320 --> 00:13:31.760
什么经历

378
00:13:31.760 --> 00:13:33.240
就是为了排查一个问题

379
00:13:33.240 --> 00:13:34.920
我需要登录多个服务器

380
00:13:35.680 --> 00:13:37.840
登录多个地方去查看文件

381
00:13:37.840 --> 00:13:38.960
去查看日志

382
00:13:39.640 --> 00:13:41.360
看一看到底是哪里发现了问题

383
00:13:42.240 --> 00:13:43.240
我们要提供这种

384
00:13:43.240 --> 00:13:44.560
可视化的日志平台之后

385
00:13:45.000 --> 00:13:46.480
我们整个的上报的日志

386
00:13:46.480 --> 00:13:47.600
全都集中在这里

387
00:13:47.960 --> 00:13:49.520
能够方便地为我们的用户

388
00:13:49.520 --> 00:13:52.880
去提供检索和分析的能力

389
00:13:53.520 --> 00:13:55.240
检索分析为什么单独去提

390
00:13:55.520 --> 00:13:56.640
因为这两个很重要

391
00:13:56.640 --> 00:14:00.080
检索是能够快速地找到我想要的日志

392
00:14:00.560 --> 00:14:02.520
分析是帮助开发者

393
00:14:02.920 --> 00:14:04.440
辅助他快速地进行

394
00:14:05.120 --> 00:14:06.720
把日志给格式化

395
00:14:06.840 --> 00:14:08.360
能够更快地去定位问题

396
00:14:09.600 --> 00:14:10.640
所以大家可以看到这图

397
00:14:10.640 --> 00:14:12.160
我们上面有很多日志类型

398
00:14:12.400 --> 00:14:13.840
大家可以看到这个图的中间

399
00:14:14.200 --> 00:14:14.880
这图的中间

400
00:14:14.880 --> 00:14:15.480
大家可以看到

401
00:14:15.480 --> 00:14:17.240
是我们内部的有很多

402
00:14:17.600 --> 00:14:18.560
这种日志类型

403
00:14:18.560 --> 00:14:19.520
这些所有的日志类型

404
00:14:19.520 --> 00:14:21.600
汇总到我们整个日志分析平台

405
00:14:21.600 --> 00:14:25.200
大家可以去查到任何一个服务的

406
00:14:25.240 --> 00:14:26.720
这样的它产生的日志

407
00:14:27.120 --> 00:14:28.640
并且是按照时间线进行

408
00:14:29.080 --> 00:14:29.760
进行串联的

409
00:14:30.240 --> 00:14:30.640
这样

410
00:14:31.760 --> 00:14:34.160
去开发者在去定位问题的时候

411
00:14:34.160 --> 00:14:38.000
就能够很快地通过这种可视化的

412
00:14:38.000 --> 00:14:38.600
这种形式

413
00:14:38.600 --> 00:14:40.640
能够知道当时发生了什么

414
00:14:42.080 --> 00:14:46.000
这是我们可视化的这种日志的平台

415
00:14:49.160 --> 00:14:50.240
接下来给大家介绍就是

416
00:14:51.000 --> 00:14:52.680
数据的这种串联的能力

417
00:14:53.960 --> 00:14:56.960
刚才我们讲了采集存储

418
00:14:57.560 --> 00:14:58.560
这个日志可视化

419
00:15:00.400 --> 00:15:01.840
这些问题只能解决

420
00:15:02.240 --> 00:15:05.160
从端上到服务器端这一段的问题

421
00:15:05.560 --> 00:15:06.400
端上发生什么

422
00:15:06.640 --> 00:15:08.800
或者换句话说能解决

423
00:15:09.280 --> 00:15:10.360
用户端上发生什么

424
00:15:10.800 --> 00:15:14.480
但是往往问题它没有像

425
00:15:15.040 --> 00:15:16.680
表面上想的那么简单

426
00:15:16.680 --> 00:15:18.400
可能问题不是出在端上

427
00:15:18.400 --> 00:15:20.720
或者端上看不出来有什么异常

428
00:15:21.400 --> 00:15:22.320
它的潜在问题

429
00:15:22.320 --> 00:15:25.160
可能是由端上去依赖的

430
00:15:25.160 --> 00:15:27.120
各种服务去引发的

431
00:15:28.360 --> 00:15:29.000
这时候怎么办

432
00:15:29.560 --> 00:15:31.640
我们这时候就需要去进行

433
00:15:31.680 --> 00:15:33.720
整个数据的这种串联能力

434
00:15:34.040 --> 00:15:34.680
这是什么意思

435
00:15:35.120 --> 00:15:36.200
那么我们讲说

436
00:15:36.200 --> 00:15:37.320
我们有共通的

437
00:15:37.320 --> 00:15:39.520
有很多这种监控系统和日志制系统

438
00:15:40.080 --> 00:15:42.240
那么Logan是解决端上的这种日志系统

439
00:15:44.520 --> 00:15:47.760
那么当这个端上有一次异常的时候

440
00:15:48.400 --> 00:15:50.440
我们再通过端上信息

441
00:15:50.880 --> 00:15:53.160
再去其他服务中

442
00:15:53.600 --> 00:15:59.720
把和端上发上异常的信息给串联起来

443
00:15:59.720 --> 00:16:03.360
其实有类似关联把和异常相关的信息

444
00:16:03.360 --> 00:16:04.600
全部采集出来

445
00:16:05.320 --> 00:16:05.760
这样

446
00:16:05.760 --> 00:16:09.200
就不仅能够去分析定位出

447
00:16:09.240 --> 00:16:10.400
端上发生什么

448
00:16:11.000 --> 00:16:12.880
能够看到整个链路上

449
00:16:12.880 --> 00:16:13.600
都发生了什么

450
00:16:14.400 --> 00:16:15.600
这是我们讲的

451
00:16:15.600 --> 00:16:17.240
数据串联能力的这一块

452
00:16:18.320 --> 00:16:20.360
这一块实际上

453
00:16:20.880 --> 00:16:22.320
我们前端日志系统

454
00:16:22.440 --> 00:16:26.680
实际上是为其他的监控系统提供了什么

455
00:16:26.680 --> 00:16:30.000
提供了在端上的上下文信息

456
00:16:30.680 --> 00:16:31.240
上下文信息

457
00:16:33.040 --> 00:16:34.320
我们接下来详细看一下

458
00:16:34.320 --> 00:16:35.560
串联上的设计

459
00:16:35.720 --> 00:16:37.840
这是一个架构的示意图

460
00:16:38.120 --> 00:16:39.360
从前端角度来讲

461
00:16:39.960 --> 00:16:41.040
我们有监控

462
00:16:41.040 --> 00:16:42.720
我们还有监控SDK

463
00:16:42.720 --> 00:16:45.920
监控SDK当它去发起一个异常

464
00:16:46.320 --> 00:16:47.640
或者上报异常的时候

465
00:16:47.640 --> 00:16:48.920
它一定会发一个网络请求

466
00:16:49.480 --> 00:16:51.040
发起网络请求的时候

467
00:16:51.040 --> 00:16:52.600
我们会在网络API中

468
00:16:52.600 --> 00:16:55.560
会生成一个唯一的traceID

469
00:16:56.320 --> 00:16:59.160
然后traceID其实就是表明

470
00:16:59.160 --> 00:17:00.240
这是一次请求的

471
00:17:00.240 --> 00:17:01.440
这样一个链路的ID

472
00:17:02.600 --> 00:17:05.320
这个traceID也会记到我们Logan SDK上

473
00:17:05.360 --> 00:17:07.760
因此Logan SDK当时

474
00:17:07.760 --> 00:17:11.240
上下文所发生的一切的日志的行为

475
00:17:11.240 --> 00:17:13.840
都会与traceID进行关联

476
00:17:14.800 --> 00:17:16.800
这样它们分别上传到后端之后

477
00:17:16.800 --> 00:17:19.480
我们再去查日志的时候

478
00:17:19.480 --> 00:17:21.600
就可以通过traceID去

479
00:17:22.240 --> 00:17:27.000
把和一次用户请求所有的这种服务端的

480
00:17:27.040 --> 00:17:28.760
这样的一个链路给抓取出来

481
00:17:29.240 --> 00:17:29.680
抓取出来

482
00:17:30.160 --> 00:17:30.760
抓取出来之后

483
00:17:30.760 --> 00:17:32.640
就能够知道

484
00:17:32.640 --> 00:17:34.800
当时用户端发生了什么

485
00:17:35.240 --> 00:17:38.240
以及用户端所产生的这种

486
00:17:38.240 --> 00:17:39.880
比如说点击查询

487
00:17:39.880 --> 00:17:42.240
或者某一次这种交互

488
00:17:42.680 --> 00:17:44.520
它对应到服务端发生了什么

489
00:17:45.200 --> 00:17:45.560
这样

490
00:17:45.560 --> 00:17:47.880
就把整个用户的场景

491
00:17:47.920 --> 00:17:48.760
给串联起来了

492
00:17:49.840 --> 00:17:51.960
这是我们串联的这样一个设计

493
00:17:51.960 --> 00:17:53.000
但是串联的设计

494
00:17:55.080 --> 00:17:56.400
还是有很多挑战的

495
00:17:56.400 --> 00:17:57.280
比如说我们后端

496
00:17:57.280 --> 00:17:58.760
其实它的整个服务的

497
00:17:59.240 --> 00:18:00.680
服务的体量非常大

498
00:18:01.640 --> 00:18:02.920
然后有很多个系统

499
00:18:03.720 --> 00:18:04.600
那这样

500
00:18:04.600 --> 00:18:07.240
我们可能就要一一进行集成对接

501
00:18:07.640 --> 00:18:08.400
然后保障说

502
00:18:08.400 --> 00:18:09.720
我们能把数据给抓出来

503
00:18:11.040 --> 00:18:11.560
当然了

504
00:18:11.600 --> 00:18:12.800
可能大家心里会有疑问

505
00:18:12.840 --> 00:18:14.200
就是说什么疑问呢

506
00:18:14.760 --> 00:18:16.200
如果我们监控系统上

507
00:18:16.560 --> 00:18:17.320
监控系统上

508
00:18:18.480 --> 00:18:20.760
这个没有产生网络请求这种

509
00:18:21.080 --> 00:18:21.680
没有网络请求

510
00:18:21.680 --> 00:18:23.040
可能你就没有traceID

511
00:18:23.960 --> 00:18:25.200
当然没有网络请求的这种

512
00:18:28.120 --> 00:18:29.200
它就不涉及到

513
00:18:29.200 --> 00:18:30.320
我服务端发生了什么

514
00:18:30.440 --> 00:18:32.600
我只有在Logan上

515
00:18:33.000 --> 00:18:34.920
能够记录的这种端上的日志

516
00:18:35.080 --> 00:18:36.760
就足够大家去分析问题了

517
00:18:37.480 --> 00:18:37.800
对

518
00:18:38.080 --> 00:18:39.040
所以这是两类

519
00:18:39.320 --> 00:18:41.680
一类是当没有网络请求的时候

520
00:18:41.680 --> 00:18:42.560
端上发生什么

521
00:18:42.560 --> 00:18:44.400
那么直接用Logan的日志

522
00:18:44.400 --> 00:18:47.680
就能够解决和定位到说我当时发生什么

523
00:18:47.680 --> 00:18:49.200
如果有网络请求的时候

524
00:18:49.200 --> 00:18:51.080
那么Logan的日志

525
00:18:51.080 --> 00:18:52.960
再加上网络请求中

526
00:18:53.320 --> 00:18:55.680
一系列后端服务的这种日志

527
00:18:55.680 --> 00:18:57.280
那么也能够定位出

528
00:18:57.280 --> 00:18:58.520
当时用户发生了什么

529
00:18:59.880 --> 00:19:01.040
这是两大类

530
00:19:02.760 --> 00:19:03.040
好

531
00:19:03.040 --> 00:19:06.640
这是我们在整个日志的串联设计上的

532
00:19:06.960 --> 00:19:08.360
整个的思路

533
00:19:08.360 --> 00:19:08.680
对

534
00:19:09.760 --> 00:19:11.800
接下来是我们的数据安全

535
00:19:11.840 --> 00:19:12.800
和可靠性保障

536
00:19:13.520 --> 00:19:15.560
那么数据安全这里实际上

537
00:19:16.000 --> 00:19:17.240
我们主要是

538
00:19:18.640 --> 00:19:21.360
本地的这种加密和加密传输

539
00:19:22.720 --> 00:19:23.920
安全后面可能还有

540
00:19:24.240 --> 00:19:26.120
按业务线的这种权限

541
00:19:26.160 --> 00:19:28.880
以及按用户角色的这种权限

542
00:19:29.320 --> 00:19:32.960
保障整个的日志的这种数据安全

543
00:19:33.400 --> 00:19:35.560
当然这里其实就是涉及到了

544
00:19:35.560 --> 00:19:37.000
端上的这种存储安全

545
00:19:37.280 --> 00:19:38.800
网络传输中的传输安全

546
00:19:39.120 --> 00:19:41.040
以及日志到了服务端之后

547
00:19:41.040 --> 00:19:42.160
它如何规范化使用

548
00:19:42.640 --> 00:19:43.680
在这三点

549
00:19:43.760 --> 00:19:44.840
我们做了一些事情

550
00:19:45.480 --> 00:19:49.280
可用性这里我们主要会设定一些指标

551
00:19:49.360 --> 00:19:51.360
我举个例子

552
00:19:51.720 --> 00:19:53.840
比如说端上的这种存储和上报成功率

553
00:19:54.200 --> 00:19:55.760
当然我们指标会有点多

554
00:19:55.760 --> 00:19:57.080
我这里提的是一些

555
00:19:57.800 --> 00:19:59.120
典型的关键的指标

556
00:19:59.240 --> 00:19:59.840
供大家参考

557
00:19:59.840 --> 00:20:00.800
比如说端上的

558
00:20:00.800 --> 00:20:03.920
我们会有存储成功率和上报成功率

559
00:20:04.840 --> 00:20:06.960
在服务器这里主要是接口的

560
00:20:07.000 --> 00:20:08.200
整个性能的一些指标

561
00:20:08.760 --> 00:20:09.000
对

562
00:20:10.240 --> 00:20:12.840
最后在Logan的日志分析平台

563
00:20:13.040 --> 00:20:15.120
比如说我们会更偏向于看

564
00:20:15.360 --> 00:20:17.720
整个我去取一段日志

565
00:20:18.040 --> 00:20:19.600
能够格式化展示出来整个

566
00:20:21.560 --> 00:20:22.440
它的性能是怎么样的

567
00:20:23.560 --> 00:20:27.400
这是我们整个在数据安全和可行性保障

568
00:20:28.080 --> 00:20:28.920
这个领域的这一个设计

569
00:20:31.800 --> 00:20:35.640
以上就是Logan整个架构和设计

570
00:20:37.040 --> 00:20:39.640
那么大家听完整个的架构设计之后

571
00:20:39.920 --> 00:20:42.120
可能心里还有一个疑问就是

572
00:20:42.480 --> 00:20:43.360
我能用它做什么

573
00:20:43.720 --> 00:20:44.680
我们内部怎么用

574
00:20:45.200 --> 00:20:46.760
所以接下来我给大家

575
00:20:47.080 --> 00:20:49.240
我今天带来三个小的案例

576
00:20:49.400 --> 00:20:50.280
这三个小的案例

577
00:20:50.400 --> 00:20:53.200
都是我们在日常工作当中

578
00:20:53.200 --> 00:20:55.640
可能每天都会碰到发生的

579
00:20:55.640 --> 00:20:56.800
然后我们看一看

580
00:20:57.040 --> 00:20:58.200
在这三个场景下

581
00:20:58.200 --> 00:21:00.640
我们怎么利用Logan的日志系统

582
00:21:00.640 --> 00:21:02.760
能够快速进行定位问题

583
00:21:03.880 --> 00:21:06.480
第一个问题是上两个月

584
00:21:06.480 --> 00:21:07.440
8月份发生的

585
00:21:07.800 --> 00:21:08.840
大家可以看到

586
00:21:08.840 --> 00:21:10.760
我们PPT的这张图

587
00:21:10.760 --> 00:21:12.320
我给大家放一下

588
00:21:14.120 --> 00:21:14.960
大家可以看到

589
00:21:15.440 --> 00:21:18.120
当发现跳转点评APP的时候

590
00:21:19.800 --> 00:21:20.760
每日福利这个页

591
00:21:21.440 --> 00:21:22.320
它会跳两次

592
00:21:22.880 --> 00:21:23.040
会跳两次

593
00:21:23.760 --> 00:21:23.880
对

594
00:21:24.120 --> 00:21:25.520
这就是从用户角度来讲

595
00:21:25.800 --> 00:21:28.760
这发生了一个不符合预期的行为

596
00:21:29.480 --> 00:21:30.400
不符合预期的行为

597
00:21:30.600 --> 00:21:32.800
到底这个原因是什么

598
00:21:33.000 --> 00:21:34.520
对如果是说

599
00:21:34.760 --> 00:21:35.720
人工去复现

600
00:21:35.720 --> 00:21:36.760
这就很难

601
00:21:37.040 --> 00:21:37.520
很难

602
00:21:37.520 --> 00:21:40.280
因为工程师

603
00:21:40.280 --> 00:21:42.680
工程师我们经常大部分的问题

604
00:21:42.680 --> 00:21:43.920
都是不可复现的

605
00:21:44.320 --> 00:21:44.560
对

606
00:21:44.840 --> 00:21:46.640
如果是说你拿到个问题

607
00:21:46.640 --> 00:21:47.760
说我一下子就复现了

608
00:21:47.920 --> 00:21:50.040
可能是研发过程中的质量把控的不好

609
00:21:50.040 --> 00:21:50.280
对

610
00:21:51.680 --> 00:21:54.160
我相信研发过程质量控好的时候

611
00:21:54.200 --> 00:21:56.440
面对现实问题的时候

612
00:21:57.280 --> 00:22:00.320
不可复现可能是绝大部分场景下

613
00:22:00.320 --> 00:22:02.400
我们容易发生的事

614
00:22:03.160 --> 00:22:04.320
在这个Case下

615
00:22:04.320 --> 00:22:05.680
我们怎么去解决问题

616
00:22:05.960 --> 00:22:09.760
我们就通过日志平台

617
00:22:10.040 --> 00:22:11.760
用户进行主动地上报

618
00:22:11.760 --> 00:22:14.320
然后我们通过日志平台可以看到

619
00:22:15.320 --> 00:22:16.880
查询到这份日志

620
00:22:16.880 --> 00:22:17.760
首先我们得知道

621
00:22:18.280 --> 00:22:19.200
查询到这份日志

622
00:22:19.200 --> 00:22:22.640
然后有了清晰化的日志之后

623
00:22:22.640 --> 00:22:24.600
我们立刻就能定位了

624
00:22:24.720 --> 00:22:26.640
发现原来是用户端

625
00:22:27.280 --> 00:22:29.400
缓存了整个我们的链接

626
00:22:30.000 --> 00:22:31.920
所以当看到这个日志的时候

627
00:22:31.920 --> 00:22:34.040
我相信大家很多开发者都有感触

628
00:22:34.520 --> 00:22:37.680
当你面对一些异常或者bug的时候

629
00:22:37.680 --> 00:22:38.600
说不能复现

630
00:22:39.920 --> 00:22:40.640
明思苦想

631
00:22:40.640 --> 00:22:42.800
可能不太容易知道说问题发生在在哪

632
00:22:42.800 --> 00:22:44.640
但当你去看到一些

633
00:22:44.640 --> 00:22:46.240
关键路径的日志的时候

634
00:22:46.680 --> 00:22:46.880
是吧

635
00:22:46.880 --> 00:22:48.160
大家都会说恍然大悟

636
00:22:48.440 --> 00:22:49.200
问题就在这

637
00:22:49.680 --> 00:22:51.520
你能很快地识别出来

638
00:22:51.560 --> 00:22:52.280
问题在哪里

639
00:22:53.640 --> 00:22:54.720
所以这也就是说

640
00:22:54.720 --> 00:22:56.360
我们日常在排查问题的时候

641
00:22:56.560 --> 00:22:57.440
这样一个Case

642
00:22:57.840 --> 00:23:01.960
通过我们Logan去查到了用户在

643
00:23:03.640 --> 00:23:05.480
跳转链路上由于缓存

644
00:23:05.520 --> 00:23:06.920
所以引起了两次跳转

645
00:23:07.040 --> 00:23:08.880
所以很快地就能去进行

646
00:23:09.280 --> 00:23:10.120
相应地这种修复

647
00:23:10.520 --> 00:23:11.280
因为缓存这类问题

648
00:23:11.280 --> 00:23:11.720
大家知道

649
00:23:11.720 --> 00:23:12.840
缓存这类问题就是

650
00:23:13.400 --> 00:23:14.760
不是每个人都能复现的

651
00:23:15.120 --> 00:23:16.120
它有很多场景下

652
00:23:16.160 --> 00:23:16.840
才有可能复现的

653
00:23:17.400 --> 00:23:19.760
这就是一个案例

654
00:23:19.960 --> 00:23:20.600
这是一个案例

655
00:23:21.560 --> 00:23:22.040
案例二

656
00:23:22.880 --> 00:23:26.120
案例二也是最近发现的

657
00:23:26.920 --> 00:23:27.840
用户反馈上

658
00:23:27.840 --> 00:23:29.160
我处于WiFi状态

659
00:23:29.640 --> 00:23:31.520
但是播放视频的时候

660
00:23:31.520 --> 00:23:33.240
会提示你

661
00:23:33.240 --> 00:23:35.200
你当前没在

662
00:23:35.200 --> 00:23:36.600
在非Wifi环境下

663
00:23:37.040 --> 00:23:37.200
对

664
00:23:37.200 --> 00:23:38.160
这是一个很常见的

665
00:23:38.480 --> 00:23:40.520
由于很多APP

666
00:23:40.520 --> 00:23:42.760
都会有这样的这种产品设计

667
00:23:42.760 --> 00:23:46.040
当你从WiFi切换到非WiFi的时候

668
00:23:46.040 --> 00:23:47.200
会给这样一个提示

669
00:23:47.720 --> 00:23:48.760
但是从用户角度说

670
00:23:49.320 --> 00:23:50.680
我现在是WiFi状态

671
00:23:50.680 --> 00:23:51.080
为什么

672
00:23:51.080 --> 00:23:52.120
你给我这个提示

673
00:23:52.680 --> 00:23:53.360
给我这个提示

674
00:23:53.840 --> 00:23:55.520
这就是一个不符合预期的行为

675
00:23:56.600 --> 00:23:57.640
这个行为实际上

676
00:23:57.640 --> 00:24:02.520
我们通过日志去进行分析

677
00:24:02.520 --> 00:24:04.840
大家看这份日志和刚才日志不一样了

678
00:24:05.800 --> 00:24:06.800
因为我们说

679
00:24:06.800 --> 00:24:07.920
我刚才提到了Logan

680
00:24:08.320 --> 00:24:10.240
汇聚了所有端上的

681
00:24:10.720 --> 00:24:12.640
很多分类的日志

682
00:24:12.640 --> 00:24:15.080
这个日志其实就是网络状态和

683
00:24:15.080 --> 00:24:16.720
的一些发生的变化

684
00:24:17.640 --> 00:24:18.120
这样的日志

685
00:24:18.120 --> 00:24:20.720
刚才的是关键的路径

686
00:24:20.960 --> 00:24:21.160
对

687
00:24:21.840 --> 00:24:23.440
你想跳转的目标

688
00:24:23.480 --> 00:24:24.320
UR是什么

689
00:24:24.800 --> 00:24:26.240
是另外一个日志

690
00:24:26.720 --> 00:24:28.800
这个是一个整个日志发生的

691
00:24:28.800 --> 00:24:29.760
这样一个网络状态的

692
00:24:29.760 --> 00:24:31.520
这样一个切换的日志

693
00:24:31.520 --> 00:24:33.200
所以通过这个状态

694
00:24:33.200 --> 00:24:34.240
就能分析出来

695
00:24:34.760 --> 00:24:38.560
原来是在进入前台之前

696
00:24:38.600 --> 00:24:40.480
就受到了网络发生变化

697
00:24:42.240 --> 00:24:42.720
这样

698
00:24:43.680 --> 00:24:49.600
其实是开发中一个很常见的问题

699
00:24:50.920 --> 00:24:52.280
由于网络延迟

700
00:24:52.360 --> 00:24:54.120
导致前端

701
00:24:54.120 --> 00:24:56.600
导致前端判断的时序发生了错误

702
00:24:57.360 --> 00:25:00.440
我明明其实已经到前台了

703
00:25:00.440 --> 00:25:02.480
但是我去判定说

704
00:25:03.720 --> 00:25:06.280
我是处于WiFi还是非WiFi状态下

705
00:25:06.720 --> 00:25:08.440
造成了这样一个时差

706
00:25:08.680 --> 00:25:11.280
这个时差就导致了提示的错误

707
00:25:12.120 --> 00:25:13.720
当然可能修复起来比较简单

708
00:25:13.960 --> 00:25:14.640
你在二次

709
00:25:14.640 --> 00:25:17.760
你在弹窗之前再判断一下

710
00:25:17.960 --> 00:25:18.680
可能就了

711
00:25:19.360 --> 00:25:21.240
但是这个也是一个

712
00:25:21.680 --> 00:25:22.600
很小的一个问题

713
00:25:22.600 --> 00:25:23.880
但是通过整个

714
00:25:23.880 --> 00:25:26.040
我们可以看到日志上的一些

715
00:25:26.560 --> 00:25:28.480
日志上的这样一个过程

716
00:25:28.480 --> 00:25:30.560
就能够很快的去定位出这个问题

717
00:25:31.400 --> 00:25:33.960
这是我带来了这个案例二

718
00:25:35.160 --> 00:25:39.880
案例三和刚才两个案例不太一样

719
00:25:39.920 --> 00:25:43.120
案例三 我找了一个

720
00:25:43.360 --> 00:25:44.640
能够串联上下游

721
00:25:44.640 --> 00:25:45.520
这样的监控系统

722
00:25:45.520 --> 00:25:46.600
来帮助这个区域

723
00:25:47.040 --> 00:25:48.600
进行日志排查的一个Case

724
00:25:49.800 --> 00:25:50.400
这个Case是什么

725
00:25:50.400 --> 00:25:52.040
其实就是监控系统

726
00:25:52.400 --> 00:25:54.480
监控系统发现了一个异常

727
00:25:55.400 --> 00:25:57.640
它会进行异常的上报

728
00:25:58.000 --> 00:25:58.400
异常上报

729
00:25:58.400 --> 00:26:01.160
比如说发生了一个网络的错误

730
00:26:02.520 --> 00:26:03.960
实际上它发生异常之后

731
00:26:04.120 --> 00:26:05.360
它就会生成刚才我提到了

732
00:26:05.360 --> 00:26:06.560
会生成一个traceID

733
00:26:07.960 --> 00:26:09.280
有了traceID呢

734
00:26:09.320 --> 00:26:12.920
Logan的日志系统会把当时

735
00:26:13.560 --> 00:26:14.760
端上发生了什么事情

736
00:26:14.880 --> 00:26:16.680
跟traceID进行关联

737
00:26:17.520 --> 00:26:20.000
所以我也会有一份异常的数据

738
00:26:21.200 --> 00:26:21.920
异常数据

739
00:26:22.120 --> 00:26:25.080
最终整个我们后端的这种日志系统

740
00:26:25.240 --> 00:26:28.080
都会带上这个traceID

741
00:26:28.360 --> 00:26:30.120
根据刚才我们提到了

742
00:26:30.160 --> 00:26:31.880
说发生异常之后

743
00:26:32.200 --> 00:26:32.920
有了traceID

744
00:26:32.960 --> 00:26:34.160
我们在根据纯traceID

745
00:26:34.200 --> 00:26:37.160
把散落在各个服务中的日志

746
00:26:37.160 --> 00:26:38.040
再给抓出来

747
00:26:38.400 --> 00:26:39.240
抓出来之后

748
00:26:39.240 --> 00:26:41.240
就能够很快速地定位出

749
00:26:41.240 --> 00:26:42.600
我们当时这个问题是什么

750
00:26:43.120 --> 00:26:45.400
所以能够

751
00:26:45.880 --> 00:26:46.960
大家通过这个图上

752
00:26:46.960 --> 00:26:47.720
就能看到说

753
00:26:47.880 --> 00:26:49.440
最终串联之后

754
00:26:49.440 --> 00:26:50.880
这几份日志放在一起

755
00:26:50.880 --> 00:26:53.880
就能够一眼定位出我们问题发生在哪里

756
00:26:55.720 --> 00:26:57.240
这是这个案例三

757
00:26:57.280 --> 00:26:59.000
所以这三个小案例

758
00:26:59.040 --> 00:27:02.040
大家可以看到在开发日常当中

759
00:27:02.080 --> 00:27:03.080
其实经常遇到

760
00:27:03.120 --> 00:27:04.600
当然我们还有很多复杂的

761
00:27:05.000 --> 00:27:07.360
还有很多复杂的这种问题

762
00:27:07.520 --> 00:27:07.800
比如说

763
00:27:08.840 --> 00:27:10.600
这周我们正在解决的一个问题是

764
00:27:12.040 --> 00:27:13.560
我们有一个页面

765
00:27:13.560 --> 00:27:16.040
它的在不同APP里

766
00:27:16.120 --> 00:27:19.400
因为我们公司有很多跨端跨平台开发的

767
00:27:20.000 --> 00:27:21.520
这样的界面在不同APP里边

768
00:27:21.520 --> 00:27:22.400
比如说在美团APP里

769
00:27:23.120 --> 00:27:23.960
和在自由APP里

770
00:27:24.000 --> 00:27:26.040
它的性能反应的不一样

771
00:27:27.120 --> 00:27:27.760
在美团里

772
00:27:27.760 --> 00:27:30.120
可能接口的反应速度会很快

773
00:27:30.120 --> 00:27:31.160
可能三四百毫秒

774
00:27:31.640 --> 00:27:32.640
但是在自由APP里

775
00:27:32.840 --> 00:27:35.200
它的接口的延迟性就很高

776
00:27:35.600 --> 00:27:37.920
突然间可能到了几千毫秒

777
00:27:38.600 --> 00:27:42.640
这一类可能就是属于

778
00:27:44.440 --> 00:27:45.440
排查问题中比较困难的

779
00:27:46.160 --> 00:27:49.000
这个可能我们就要去串联说

780
00:27:49.440 --> 00:27:50.560
容器发生了什么事

781
00:27:51.440 --> 00:27:52.560
网络发生了什么事

782
00:27:53.120 --> 00:27:53.840
甚至说

783
00:27:54.520 --> 00:27:56.040
当你这个容器启动前

784
00:27:56.080 --> 00:27:56.920
和网络发生前

785
00:27:56.960 --> 00:27:59.040
其他前置还发生了什么事情

786
00:27:59.760 --> 00:28:00.160
这样

787
00:28:00.440 --> 00:28:02.360
只有把跨业务的这种日志

788
00:28:02.720 --> 00:28:03.880
全能串联起来之后

789
00:28:03.880 --> 00:28:04.720
才能排查这个问题

790
00:28:05.400 --> 00:28:06.760
所以这也是我开场提到的

791
00:28:07.840 --> 00:28:08.760
很多业务

792
00:28:08.760 --> 00:28:10.600
就是我们大多数情况下来讲

793
00:28:10.600 --> 00:28:12.880
各个业务都会有自己的日志通道

794
00:28:14.200 --> 00:28:14.360
日志通道

795
00:28:15.160 --> 00:28:16.640
但是它只能记住

796
00:28:16.640 --> 00:28:18.040
自己业务当时发生什么

797
00:28:18.480 --> 00:28:19.640
我们可能会有一些通用的

798
00:28:19.640 --> 00:28:20.280
比如说我们

799
00:28:20.760 --> 00:28:22.520
我们大多数情况下

800
00:28:23.040 --> 00:28:24.320
很多同学可能大多数情况下

801
00:28:24.320 --> 00:28:25.200
比如说网络库

802
00:28:25.200 --> 00:28:25.960
它是一个通用的

803
00:28:26.640 --> 00:28:27.400
各个业务都会用

804
00:28:29.680 --> 00:28:31.520
所以说你记录业务的可能

805
00:28:31.520 --> 00:28:33.360
你还要去查看说

806
00:28:33.360 --> 00:28:35.400
网络这一块我发生了什么

807
00:28:36.760 --> 00:28:37.440
还有一种情况是说

808
00:28:37.680 --> 00:28:38.840
我本地存储

809
00:28:39.200 --> 00:28:40.600
数据库存储这块可能也是通用的

810
00:28:41.080 --> 00:28:42.480
我还想知道说

811
00:28:42.960 --> 00:28:44.680
存储这个领域我发生了什么

812
00:28:45.360 --> 00:28:46.400
所以这就是说

813
00:28:48.040 --> 00:28:50.800
我们通过统一的这样的一个日志

814
00:28:51.080 --> 00:28:55.200
那么前端各个从架构分层上来看

815
00:28:55.400 --> 00:28:57.680
各个分层的日志

816
00:28:57.680 --> 00:28:58.520
我们都记录下来

817
00:28:59.280 --> 00:29:02.680
比如说我们和我们的动态化容器团队的吧

818
00:29:02.680 --> 00:29:04.560
进行合作

819
00:29:04.800 --> 00:29:06.120
把和容器层的日志

820
00:29:06.240 --> 00:29:08.320
我们进行存储

821
00:29:09.040 --> 00:29:11.440
跟网络的团队进行合作

822
00:29:11.440 --> 00:29:14.200
把所有跟网络组件相关的日志进行存储

823
00:29:14.800 --> 00:29:18.640
然后把和本地数据库相关的也进行

824
00:29:19.080 --> 00:29:19.560
这样

825
00:29:19.560 --> 00:29:21.200
很多通用的这些数据

826
00:29:21.640 --> 00:29:23.440
很多通用的数据建设成功之后

827
00:29:23.840 --> 00:29:24.560
建设成功之后

828
00:29:25.640 --> 00:29:26.640
很多新业务

829
00:29:27.280 --> 00:29:30.320
哪怕你仅仅是在我们APP上写个H5

830
00:29:31.840 --> 00:29:33.880
那么你也能够知道说

831
00:29:33.880 --> 00:29:35.920
我的这个业务环境下

832
00:29:36.520 --> 00:29:37.880
有哪些基础的信息

833
00:29:37.880 --> 00:29:38.760
都发生了什么事

834
00:29:39.200 --> 00:29:39.640
这样

835
00:29:39.640 --> 00:29:41.400
就为很多开发者

836
00:29:41.400 --> 00:29:44.400
提供了比较易用的这样一个日志

837
00:29:44.400 --> 00:29:45.320
的常态分析的手段

838
00:29:45.840 --> 00:29:47.760
来帮助大家非常低成本地

839
00:29:47.760 --> 00:29:49.680
去进行这个问题的定位

840
00:29:50.480 --> 00:29:53.560
这是刚才的三个案例

841
00:29:53.800 --> 00:29:55.600
希望大家能够通过这三个案例

842
00:29:56.040 --> 00:29:56.840
能够知道说

843
00:29:56.840 --> 00:29:57.760
我们在前面

844
00:29:57.760 --> 00:29:59.800
在日志去建设过程当中

845
00:30:00.240 --> 00:30:01.880
能切实地去解决我们

846
00:30:02.280 --> 00:30:03.600
同学们的实际问题

847
00:30:05.720 --> 00:30:07.040
Logan在美团的实践

848
00:30:07.280 --> 00:30:10.480
我们目前几乎美团所有的APP

849
00:30:10.960 --> 00:30:11.960
都已经接入Logan

850
00:30:11.960 --> 00:30:14.480
然后我放了两份数据

851
00:30:14.480 --> 00:30:16.040
一个是Web的

852
00:30:16.560 --> 00:30:17.880
然后Web的PV量

853
00:30:18.000 --> 00:30:20.000
也就是说接了 Logan

854
00:30:20.160 --> 00:30:21.880
可能每一天的pv量

855
00:30:21.920 --> 00:30:23.360
可能都在2亿多

856
00:30:24.600 --> 00:30:26.720
小程序整个这块可能有700万+

857
00:30:27.120 --> 00:30:27.280
对

858
00:30:27.280 --> 00:30:29.320
当然这个其实不算是

859
00:30:29.320 --> 00:30:30.640
不是日志量

860
00:30:30.680 --> 00:30:30.840
对

861
00:30:30.880 --> 00:30:32.560
因为前面我提到了

862
00:30:32.600 --> 00:30:34.120
我们的日志不是全量上报

863
00:30:34.160 --> 00:30:35.080
是按需上报

864
00:30:35.600 --> 00:30:36.600
我当有问题的时候

865
00:30:36.600 --> 00:30:37.760
我才去上报

866
00:30:37.760 --> 00:30:38.000
对

867
00:30:38.960 --> 00:30:40.000
这样能够

868
00:30:41.000 --> 00:30:42.320
比较好的去

869
00:30:42.880 --> 00:30:43.960
一方面是说

870
00:30:43.960 --> 00:30:45.000
因为刚才提到说

871
00:30:45.000 --> 00:30:47.200
我们很多前端上的

872
00:30:47.200 --> 00:30:49.000
一些分层的架构都会存储

873
00:30:49.360 --> 00:30:50.840
所以它的日志会很大

874
00:30:51.440 --> 00:30:53.200
因此我们采用这种按需上报

875
00:30:53.840 --> 00:30:56.240
一方面能够减轻服务端的压力

876
00:30:56.720 --> 00:30:57.640
减轻用户端的流量

877
00:30:58.120 --> 00:31:00.280
其次能够更好针对性的

878
00:31:00.320 --> 00:31:01.560
进行问题的定位

879
00:31:02.920 --> 00:31:05.480
这是在美团的一些情况

880
00:31:06.400 --> 00:31:07.800
最后跟大家聊一聊

881
00:31:07.800 --> 00:31:09.320
我们目前正在做什么

882
00:31:09.320 --> 00:31:13.040
以及行业内其实整个趋势是怎么样的

883
00:31:16.560 --> 00:31:19.080
其实整个日志这块

884
00:31:19.080 --> 00:31:21.800
我还需要跟大家去有一个概念

885
00:31:21.800 --> 00:31:22.720
和大家分享一下

886
00:31:22.920 --> 00:31:25.280
日志和监控到底是什么区别

887
00:31:26.200 --> 00:31:29.360
当然我谈一谈我的理解

888
00:31:29.360 --> 00:31:31.000
和我们内部的一些情况

889
00:31:31.480 --> 00:31:32.840
因为监控更偏向于是什么

890
00:31:32.880 --> 00:31:33.560
是发现问题

891
00:31:34.360 --> 00:31:36.160
它主要是侧重于发现问题

892
00:31:36.160 --> 00:31:38.200
当然它可能会随带着

893
00:31:39.240 --> 00:31:41.320
附带一些定位问题

894
00:31:42.160 --> 00:31:44.400
日志系统更偏向于的是

895
00:31:44.400 --> 00:31:45.720
定位和分析问题

896
00:31:46.640 --> 00:31:47.760
所以这两个不太一样

897
00:31:48.240 --> 00:31:49.840
所以日志系统这块

898
00:31:50.160 --> 00:31:51.720
我们既然说我们

899
00:31:51.720 --> 00:31:53.520
它是要去定位问题的

900
00:31:53.520 --> 00:31:55.440
然后我也提到了说

901
00:31:55.920 --> 00:31:58.400
其实我们日志有很大的量的日志

902
00:31:58.400 --> 00:31:59.960
其实它都是正常的日志

903
00:32:01.320 --> 00:32:01.560
正常日志

904
00:32:01.560 --> 00:32:04.840
因为我们去记日志的时候

905
00:32:05.200 --> 00:32:07.320
大家在平时工作中也有感触

906
00:32:07.800 --> 00:32:08.880
可能很长很长

907
00:32:08.880 --> 00:32:10.120
几兆的这种日志文件

908
00:32:10.680 --> 00:32:12.440
关键的日志的异常信息

909
00:32:12.480 --> 00:32:13.800
可能就那么一页两页

910
00:32:14.440 --> 00:32:17.440
绝大部分的日志都是这种正常的

911
00:32:17.880 --> 00:32:18.160
对

912
00:32:18.160 --> 00:32:19.440
所以我们一直在思考

913
00:32:19.440 --> 00:32:22.480
就是说怎么去有这么大量的这种日志

914
00:32:22.480 --> 00:32:23.760
我们去提供它整个日志

915
00:32:23.760 --> 00:32:24.640
这种利用的价值

916
00:32:25.320 --> 00:32:25.560
对

917
00:32:26.080 --> 00:32:27.360
这里可能有几点

918
00:32:27.360 --> 00:32:29.080
第一点就是大数据的日志分析

919
00:32:30.320 --> 00:32:31.240
日志分析这块

920
00:32:31.240 --> 00:32:34.360
一直是我们需要去攻克去做的

921
00:32:34.360 --> 00:32:34.880
为什么

922
00:32:35.280 --> 00:32:37.240
因为开发者上报了日志

923
00:32:37.240 --> 00:32:38.280
他去排查问题的时候

924
00:32:38.280 --> 00:32:39.800
他一定会用到分析工具

925
00:32:40.200 --> 00:32:41.040
所以分析工具

926
00:32:41.080 --> 00:32:43.520
是和一线RD息息相关的

927
00:32:44.800 --> 00:32:45.800
如果他明确知道

928
00:32:45.800 --> 00:32:46.960
我要分析哪份文件

929
00:32:47.480 --> 00:32:50.120
我们只要给他结构化的展示

930
00:32:50.120 --> 00:32:52.840
帮他把各种场景下的进行串联

931
00:32:52.840 --> 00:32:53.720
就了

932
00:32:54.440 --> 00:32:55.920
当然还有很多情况下

933
00:32:55.920 --> 00:32:58.240
就是说可能它仅仅是一些风险的提示

934
00:33:00.320 --> 00:33:03.440
他需要在很大量的这种日志上

935
00:33:03.440 --> 00:33:04.880
去分析说我有什么问题

936
00:33:05.200 --> 00:33:07.160
这个时候可能我们就要进行一些

937
00:33:07.680 --> 00:33:09.160
智能检索或者特定查询

938
00:33:09.560 --> 00:33:12.080
然后再通过可视化的手段帮助

939
00:33:12.120 --> 00:33:14.160
因为这只是辅助研发工程师

940
00:33:14.200 --> 00:33:15.640
进行问题的分析

941
00:33:16.120 --> 00:33:16.760
这是第一点

942
00:33:17.400 --> 00:33:17.960
第二点

943
00:33:18.040 --> 00:33:20.280
就是异常的这种主动感知

944
00:33:21.280 --> 00:33:23.040
这个异常的主动感知

945
00:33:23.680 --> 00:33:26.840
这里其实有两方面

946
00:33:26.840 --> 00:33:29.040
一方面是日志到了服务端之后

947
00:33:29.400 --> 00:33:30.240
我在服务端

948
00:33:31.720 --> 00:33:34.440
通过我们积极学习的模型去看

949
00:33:34.960 --> 00:33:37.000
去判定它是否是有异常的行为

950
00:33:37.680 --> 00:33:38.960
因为我前面介绍到

951
00:33:39.520 --> 00:33:41.440
我们端上记了

952
00:33:41.720 --> 00:33:43.800
按照分层记了很多日志

953
00:33:44.680 --> 00:33:46.680
你单从一层上可能看不出来异常

954
00:33:46.800 --> 00:33:49.200
感觉这是个正常的行为

955
00:33:49.560 --> 00:33:50.720
但是如果你串联上

956
00:33:50.720 --> 00:33:52.800
可能在用户的行为上

957
00:33:52.800 --> 00:33:53.720
它可能就是异常的

958
00:33:54.880 --> 00:33:55.720
所以在服务端

959
00:33:55.720 --> 00:33:58.160
我们需要进行这样的一个特征分析

960
00:33:58.600 --> 00:33:59.560
还有一类是什么

961
00:33:59.560 --> 00:34:00.800
叫异常主动感知

962
00:34:00.800 --> 00:34:01.840
我们方向可以去做的

963
00:34:02.800 --> 00:34:04.000
现在可能最近几年

964
00:34:04.000 --> 00:34:05.120
也在提端智能

965
00:34:05.440 --> 00:34:07.040
端智能在端上

966
00:34:07.040 --> 00:34:09.400
我们把整个训练模型下发到端上

967
00:34:10.440 --> 00:34:11.760
由端去判定说

968
00:34:12.480 --> 00:34:14.520
当时的场景是否是个异常

969
00:34:15.640 --> 00:34:17.760
这个方向能够极大提升

970
00:34:18.160 --> 00:34:20.160
异常的这种主动发现

971
00:34:20.680 --> 00:34:23.240
由端上去主动去进行日志的上报

972
00:34:24.160 --> 00:34:26.480
然后去提前去感知我们潜在

973
00:34:26.880 --> 00:34:27.680
有哪些风险点

974
00:34:28.480 --> 00:34:29.200
这是第二块

975
00:34:29.720 --> 00:34:31.680
第三个就是全链路的日志统一

976
00:34:31.680 --> 00:34:33.200
对我们现在Logan系统

977
00:34:33.200 --> 00:34:35.640
是更偏向于是在做端上的

978
00:34:35.640 --> 00:34:37.120
整个日志统一我们做完了

979
00:34:37.640 --> 00:34:39.760
其实我们后面还有

980
00:34:40.600 --> 00:34:42.160
多个这种后端的系统

981
00:34:42.560 --> 00:34:44.080
对我们现在进行打通了

982
00:34:44.320 --> 00:34:45.200
现在进行打通了

983
00:34:46.080 --> 00:34:46.880
这种打通串联

984
00:34:47.040 --> 00:34:51.280
其实我认为是一个叫中间状态

985
00:34:52.040 --> 00:34:53.120
更合理的是说

986
00:34:53.120 --> 00:34:55.960
我们要把从前端到服务端

987
00:34:56.360 --> 00:34:59.760
网络层等整个的链路上

988
00:34:59.840 --> 00:35:00.880
在日志上

989
00:35:00.880 --> 00:35:02.760
我们可能还需要进一步的规范化

990
00:35:03.120 --> 00:35:03.480
这样

991
00:35:03.480 --> 00:35:06.360
可能很方便地进行日志的这种

992
00:35:07.640 --> 00:35:09.080
更好的可视化的展示

993
00:35:09.200 --> 00:35:11.280
能够帮助大家去快速定位问题

994
00:35:12.440 --> 00:35:13.840
因为端上发生的问题

995
00:35:13.880 --> 00:35:15.400
可能它是由于网络的抖动

996
00:35:16.200 --> 00:35:18.480
也有可能由于可能是机器的抖动

997
00:35:18.680 --> 00:35:19.800
甚至说机器坏了

998
00:35:21.400 --> 00:35:23.120
所有的这种情况都可能发生

999
00:35:23.280 --> 00:35:25.280
所以说单从端上来讲

1000
00:35:25.280 --> 00:35:27.000
可能不能看到深层的问题

1001
00:35:27.360 --> 00:35:29.200
所以只有把我们整个链路当中

1002
00:35:29.480 --> 00:35:30.520
这种日志

1003
00:35:31.440 --> 00:35:32.320
都串联起来

1004
00:35:32.760 --> 00:35:35.280
那么才能够更深层次的进行分析

1005
00:35:35.280 --> 00:35:36.720
当然还有一个

1006
00:35:36.720 --> 00:35:38.920
还有一个能够提供额外能力

1007
00:35:38.920 --> 00:35:40.360
就是你日志记的全

1008
00:35:40.360 --> 00:35:41.760
也可能提供审计的能力

1009
00:35:42.240 --> 00:35:42.440
对

1010
00:35:43.120 --> 00:35:44.560
最后一点就是我们开放数据API

1011
00:35:44.560 --> 00:35:46.560
这是我们一直在做的

1012
00:35:47.120 --> 00:35:48.000
我们有很多日志

1013
00:35:48.040 --> 00:35:48.840
有很多异常

1014
00:35:49.520 --> 00:35:50.800
但是公司内大家都知道

1015
00:35:50.800 --> 00:35:52.560
公司内可能各个业务

1016
00:35:52.560 --> 00:35:54.360
都会有自己的这种

1017
00:35:55.200 --> 00:35:56.240
可能性的保障平台

1018
00:35:57.400 --> 00:35:59.560
或者是自己的这种排查的手段工具

1019
00:36:00.240 --> 00:36:02.360
如果想让业务能够更好地

1020
00:36:02.360 --> 00:36:03.960
去利用好日志

1021
00:36:03.960 --> 00:36:07.200
我们会把按业务属性分层分类

1022
00:36:07.200 --> 00:36:08.880
然后去提供硬性的API

1023
00:36:08.880 --> 00:36:10.280
让这些日志

1024
00:36:10.560 --> 00:36:12.200
能够和它们自有的这种系统

1025
00:36:12.200 --> 00:36:14.240
能够更好的这种结合起来

1026
00:36:15.400 --> 00:36:19.520
这是我们在提升日志的这种利用率

1027
00:36:19.560 --> 00:36:20.960
和价值上的一些思考

1028
00:36:21.440 --> 00:36:24.000
那也是当前我们正在做的事情

1029
00:36:24.000 --> 00:36:26.440
和对目前行业的一些趋势的

1030
00:36:26.440 --> 00:36:27.920
这样一个建议

1031
00:36:29.920 --> 00:36:31.280
最后我们来回顾

1032
00:36:31.520 --> 00:36:34.760
回顾今天整个我分享的主题

1033
00:36:35.920 --> 00:36:38.680
在我们整个日志系统建设这块总结上

1034
00:36:38.720 --> 00:36:40.520
我又把它分成了三个阶段

1035
00:36:41.160 --> 00:36:41.920
这三个阶段

1036
00:36:42.280 --> 00:36:44.400
也是我给大家的一些建议

1037
00:36:44.440 --> 00:36:45.600
因为我们自己建设

1038
00:36:45.760 --> 00:36:48.800
其实也是按照三个阶段来的

1039
00:36:49.120 --> 00:36:50.240
最初级阶段

1040
00:36:50.240 --> 00:36:52.040
其实目标就是解决什么

1041
00:36:52.240 --> 00:36:52.680
从无到有

1042
00:36:53.360 --> 00:36:53.760
解决从无到有

1043
00:36:53.760 --> 00:36:55.760
那我解决从无到有时候

1044
00:36:55.760 --> 00:36:57.800
你就不能一下子架子搭的太大

1045
00:36:58.520 --> 00:36:59.400
我搞全链路

1046
00:36:59.400 --> 00:37:02.200
我搞把日志全部都统一起来

1047
00:37:02.360 --> 00:37:03.480
这个工程就比较大了

1048
00:37:04.280 --> 00:37:05.480
所以初期阶段

1049
00:37:05.480 --> 00:37:06.800
我们解决从无到有

1050
00:37:06.800 --> 00:37:08.120
就先解决什么

1051
00:37:08.520 --> 00:37:11.200
端上我日志能够收集上来

1052
00:37:12.240 --> 00:37:12.840
要解决什么

1053
00:37:12.840 --> 00:37:16.400
首先我们统一的这种日志的SDK

1054
00:37:17.520 --> 00:37:18.200
这是第一点

1055
00:37:18.600 --> 00:37:20.920
第二点就是整个日志的这种规范化

1056
00:37:21.600 --> 00:37:23.320
所有的那种架构的分层业务

1057
00:37:23.360 --> 00:37:26.120
我怎么样去按照我的规范化去记日志

1058
00:37:26.680 --> 00:37:27.840
这就能解决

1059
00:37:28.560 --> 00:37:29.480
从无到有了

1060
00:37:29.520 --> 00:37:33.280
我先不用管我上报高可用

1061
00:37:33.960 --> 00:37:34.680
我先打日志

1062
00:37:34.680 --> 00:37:37.520
我遇到问题的时候我能查

1063
00:37:38.160 --> 00:37:38.880
这是第一个阶段

1064
00:37:39.160 --> 00:37:40.320
能够很快的进行做

1065
00:37:40.920 --> 00:37:42.200
为什么要先做这个事

1066
00:37:42.360 --> 00:37:45.240
是因为当业务随着业务越来越复杂

1067
00:37:45.280 --> 00:37:46.120
越来越多的时候

1068
00:37:46.480 --> 00:37:47.480
你不去做这个事的时候

1069
00:37:47.520 --> 00:37:49.240
大家可能有自己的这种通道

1070
00:37:49.360 --> 00:37:51.080
再去切的时候会比较

1071
00:37:51.680 --> 00:37:52.400
你就会有周期

1072
00:37:52.440 --> 00:37:53.320
周期会越来越长

1073
00:37:53.680 --> 00:37:55.760
先解决口收集端的问题

1074
00:37:56.280 --> 00:37:57.920
然后我们再慢慢去解决

1075
00:37:57.920 --> 00:37:59.720
链路上的一些性能

1076
00:37:59.720 --> 00:38:00.840
和应用性的问题

1077
00:38:01.600 --> 00:38:03.520
所以随之而来我们就到了

1078
00:38:04.240 --> 00:38:04.920
到了第二阶段

1079
00:38:05.120 --> 00:38:05.760
就是发展阶段

1080
00:38:06.960 --> 00:38:09.080
发展阶段更偏向于它的目标是什么

1081
00:38:09.680 --> 00:38:11.640
是能够快速定位问题

1082
00:38:12.560 --> 00:38:14.400
提供更易用的

1083
00:38:14.400 --> 00:38:15.520
这样一个分析能力

1084
00:38:16.160 --> 00:38:18.720
当我们的一线工程师

1085
00:38:18.720 --> 00:38:19.640
遇到问题之后

1086
00:38:20.200 --> 00:38:22.160
它能够通过我们的平台

1087
00:38:22.160 --> 00:38:25.080
快速地能够查到相应的日志

1088
00:38:25.120 --> 00:38:26.080
能够把问题分析出来

1089
00:38:26.320 --> 00:38:28.960
这是痛点了

1090
00:38:29.680 --> 00:38:30.720
第一阶段是从无到有

1091
00:38:30.720 --> 00:38:31.520
可能日志都有了

1092
00:38:31.520 --> 00:38:33.880
我还需要半人工的时候去查

1093
00:38:34.360 --> 00:38:36.560
各种日志文件上去查看问题在哪

1094
00:38:37.280 --> 00:38:39.080
第二节阶段更偏向就是快速定位

1095
00:38:39.080 --> 00:38:40.080
所以快速定位

1096
00:38:40.080 --> 00:38:42.040
这地方包含了说我的性能

1097
00:38:42.040 --> 00:38:43.160
我在日志是传上来的

1098
00:38:43.600 --> 00:38:44.720
我传都传不上来

1099
00:38:44.840 --> 00:38:45.600
我可能就没有了

1100
00:38:45.640 --> 00:38:46.400
看不到了

1101
00:38:46.960 --> 00:38:49.360
包含我们刚才提到的

1102
00:38:49.360 --> 00:38:50.640
这种分片的上传

1103
00:38:51.320 --> 00:38:52.840
提高我们日志的上报成功率

1104
00:38:53.360 --> 00:38:54.920
包含我们做日志的

1105
00:38:54.960 --> 00:38:56.160
这种分析平台

1106
00:38:56.200 --> 00:38:59.600
帮他结构化地进行日志的这种展示

1107
00:39:00.280 --> 00:39:02.840
快速地进行筛查检索

1108
00:39:02.960 --> 00:39:05.400
能够比如我快速地去滤出说

1109
00:39:05.880 --> 00:39:06.840
我网络上

1110
00:39:06.840 --> 00:39:09.440
网络的日志有什么发生了什么事

1111
00:39:10.080 --> 00:39:11.640
我快速地去定位说

1112
00:39:11.640 --> 00:39:13.480
用户在某一个Web页面

1113
00:39:13.800 --> 00:39:15.480
它一共进了几次Web页面

1114
00:39:15.800 --> 00:39:19.440
每次这个停留时长是多少

1115
00:39:19.800 --> 00:39:22.360
然后发生了什么异常

1116
00:39:22.880 --> 00:39:24.920
对这些更偏向于说

1117
00:39:24.960 --> 00:39:26.440
要为我们开发者

1118
00:39:26.480 --> 00:39:29.040
提供更多能够还原场景的这样能力

1119
00:39:29.440 --> 00:39:30.560
还原现场发生了什么

1120
00:39:30.960 --> 00:39:31.600
有哪些异常

1121
00:39:31.960 --> 00:39:32.240
对

1122
00:39:32.240 --> 00:39:33.520
所以我们做分析平台

1123
00:39:33.520 --> 00:39:36.360
主要traceID做这种全链路

1124
00:39:37.080 --> 00:39:37.960
这是第二阶段

1125
00:39:38.560 --> 00:39:39.640
到了成熟阶段

1126
00:39:40.320 --> 00:39:41.920
可能我们就不满足说

1127
00:39:42.800 --> 00:39:44.000
用户来一个问题

1128
00:39:44.160 --> 00:39:44.720
报一个问题

1129
00:39:44.720 --> 00:39:45.520
我解决一个问题

1130
00:39:45.880 --> 00:39:47.240
我们更偏向的就是说

1131
00:39:47.600 --> 00:39:48.920
能够主动感知到

1132
00:39:49.400 --> 00:39:50.880
有哪些潜在可能的问题

1133
00:39:51.960 --> 00:39:53.360
这个时候我们就会做

1134
00:39:53.360 --> 00:39:54.720
根据大数据的

1135
00:39:54.720 --> 00:39:56.960
根据我们日志的海量日志

1136
00:39:56.960 --> 00:39:58.280
我们要去做那种日志的

1137
00:39:58.280 --> 00:39:59.800
主动的那种大数据分析

1138
00:40:00.560 --> 00:40:02.400
然后前置上报

1139
00:40:02.520 --> 00:40:03.280
我们现在正在做的

1140
00:40:03.280 --> 00:40:04.600
就是前置上报

1141
00:40:04.600 --> 00:40:05.520
其实前置上报就有了

1142
00:40:05.520 --> 00:40:07.200
类似于端智能的一个应用

1143
00:40:07.480 --> 00:40:08.840
我们在端上去判定说

1144
00:40:09.440 --> 00:40:10.400
这可能是个异常

1145
00:40:10.400 --> 00:40:10.720
对

1146
00:40:11.480 --> 00:40:13.560
我们现在还不能做到说100%确定异常

1147
00:40:13.800 --> 00:40:15.560
我们只能说它可能是一场

1148
00:40:16.040 --> 00:40:17.640
我要去告诉开发者

1149
00:40:17.760 --> 00:40:18.560
我可能是个异常

1150
00:40:18.560 --> 00:40:19.560
你需要看一下关注一下

1151
00:40:20.880 --> 00:40:24.120
然后再强化我们日志的分析平台

1152
00:40:24.120 --> 00:40:24.960
我们叫可视化分析

1153
00:40:25.320 --> 00:40:26.800
可视化的那种日志分析平台

1154
00:40:27.240 --> 00:40:29.960
来帮助我们的开发者

1155
00:40:29.960 --> 00:40:33.080
能够更快

1156
00:40:33.360 --> 00:40:37.240
比用户可能更先能感知到发生了什么

1157
00:40:37.800 --> 00:40:38.000
对

1158
00:40:38.320 --> 00:40:38.840
当然了

1159
00:40:38.880 --> 00:40:39.680
实际上

1160
00:40:39.720 --> 00:40:43.400
这个问题都是先发生在记录在感知到的

1161
00:40:43.800 --> 00:40:45.120
但是大家知道

1162
00:40:46.320 --> 00:40:47.880
日常我们遇到的这些问题

1163
00:40:47.880 --> 00:40:50.760
它绝大的绝大多数情况下

1164
00:40:50.760 --> 00:40:51.560
它都不是个案

1165
00:40:52.600 --> 00:40:55.160
因为大家如果有用户量

1166
00:40:55.160 --> 00:40:56.000
体积比较大的

1167
00:40:56.200 --> 00:40:57.160
咱们不用说特别大

1168
00:40:57.160 --> 00:41:00.240
比如说你有百万日志量的用户

1169
00:41:01.480 --> 00:41:04.200
但凡某个用户发生的问题

1170
00:41:05.320 --> 00:41:07.480
绝大多数情况下

1171
00:41:07.520 --> 00:41:09.040
都不是个案

1172
00:41:10.080 --> 00:41:10.800
都不是特例

1173
00:41:11.520 --> 00:41:13.200
总会有符合

1174
00:41:13.640 --> 00:41:16.480
发生这一类异常的一批用户

1175
00:41:16.680 --> 00:41:17.800
也会发生同类异常

1176
00:41:18.440 --> 00:41:18.600
对

1177
00:41:18.960 --> 00:41:19.520
所以有些时候

1178
00:41:19.560 --> 00:41:21.360
你看我们去排查问题

1179
00:41:21.360 --> 00:41:23.800
或者做用户做这个问题

1180
00:41:23.800 --> 00:41:24.400
复盘的时候

1181
00:41:24.400 --> 00:41:25.760
都说我这个问题

1182
00:41:25.760 --> 00:41:27.000
可能影响了多少用户

1183
00:41:28.560 --> 00:41:29.640
可能影响那波用户

1184
00:41:29.680 --> 00:41:32.960
我们就希望当影响这波用户

1185
00:41:33.000 --> 00:41:34.000
在前期的时候

1186
00:41:34.200 --> 00:41:35.320
我们就通过主动上报

1187
00:41:35.360 --> 00:41:36.240
能够知道前端的问题

1188
00:41:37.360 --> 00:41:38.560
这是成熟阶段

1189
00:41:39.120 --> 00:41:41.480
所以在建设整个阶段

1190
00:41:41.640 --> 00:41:44.240
其实如果大家有同类的这种诉求

1191
00:41:45.160 --> 00:41:45.960
也可以参考

1192
00:41:46.400 --> 00:41:47.560
刚才我给大家展示了

1193
00:41:47.560 --> 00:41:48.440
这样的一个架构图

1194
00:41:48.440 --> 00:41:50.720
然后按照整个不同的阶段

1195
00:41:50.880 --> 00:41:52.040
进行这样建设

1196
00:41:52.040 --> 00:41:53.800
这样能够更快地进行

1197
00:41:53.800 --> 00:41:54.560
在业务上

1198
00:41:54.560 --> 00:41:56.320
能够得到一些价值体现

1199
00:41:57.080 --> 00:41:58.320
你一下规划太大

1200
00:41:58.600 --> 00:42:00.000
可能我半年一年

1201
00:42:00.000 --> 00:42:01.680
我才能看到这个业务的价值

1202
00:42:02.000 --> 00:42:03.320
这样大家可能就等不到

1203
00:42:03.720 --> 00:42:05.120
所以提到初期从无到有

1204
00:42:05.120 --> 00:42:07.880
可能很快业务就能接入进来

1205
00:42:07.880 --> 00:42:10.360
就能够在应用上落地了

1206
00:42:10.680 --> 00:42:12.200
然后逐渐进行迭代

1207
00:42:12.200 --> 00:42:14.040
然后帮助大家快速进行定位

1208
00:42:14.040 --> 00:42:14.800
快速的定位

1209
00:42:14.800 --> 00:42:15.760
这里有一个很关键点

1210
00:42:15.760 --> 00:42:17.760
就是要把分析平台做好

1211
00:42:18.400 --> 00:42:20.240
分析平台其实是大家

1212
00:42:20.680 --> 00:42:21.680
非常常用的

1213
00:42:21.680 --> 00:42:23.760
对能把分析平台能结构化展示

1214
00:42:23.760 --> 00:42:24.480
这样

1215
00:42:25.040 --> 00:42:27.200
能怎么样能够得到更多的

1216
00:42:27.640 --> 00:42:28.440
一线的工程师

1217
00:42:28.440 --> 00:42:29.400
给你更多的反馈

1218
00:42:30.040 --> 00:42:31.480
因为我们做日志平台

1219
00:42:31.480 --> 00:42:34.480
其实我们是不能100%了解

1220
00:42:34.480 --> 00:42:35.200
所有应用场景的

1221
00:42:35.920 --> 00:42:36.600
所以大家说

1222
00:42:36.840 --> 00:42:39.800
我通过分析发现这一类的情况

1223
00:42:40.000 --> 00:42:41.000
我发现我定位不了

1224
00:42:41.800 --> 00:42:45.440
我需要可能增加一种分析的模式

1225
00:42:45.440 --> 00:42:47.520
甚至说一种日志类型我才能分析到

1226
00:42:48.160 --> 00:42:48.840
所以在这类

1227
00:42:49.360 --> 00:42:51.320
我们要注重这种分析平台的建设

1228
00:42:51.320 --> 00:42:53.040
然后和更多的这种

1229
00:42:53.960 --> 00:42:54.920
研发工程师互动

1230
00:42:55.400 --> 00:42:57.840
来逐渐去完善我们整个这种分析能力

1231
00:42:59.360 --> 00:43:00.800
第三阶段可能就是成熟阶段

1232
00:43:00.920 --> 00:43:02.840
这是三个阶段的回顾

1233
00:43:04.440 --> 00:43:06.040
这是今天以上

1234
00:43:06.240 --> 00:43:07.600
就是我今天给大家分享的

1235
00:43:07.600 --> 00:43:08.520
主要的内容

1236
00:43:08.520 --> 00:43:10.880
对后面其实有一个彩蛋

1237
00:43:10.920 --> 00:43:11.680
就是我们Logan

1238
00:43:11.800 --> 00:43:13.600
其实一直在很早

1239
00:43:13.640 --> 00:43:14.280
我们就开源了

1240
00:43:14.320 --> 00:43:15.480
并且在去年的时候

1241
00:43:15.520 --> 00:43:18.120
我们开源了Web端的代码

1242
00:43:18.480 --> 00:43:20.280
所以大家可以去GitHub上

1243
00:43:21.480 --> 00:43:22.400
尝试试用一下

1244
00:43:22.840 --> 00:43:25.480
然后上面有我们的GitHub的地址

1245
00:43:25.480 --> 00:43:28.920
和我们微信的这种开发者的交流群

1246
00:43:29.360 --> 00:43:30.480
大家也可以关注一下

1247
00:43:30.840 --> 00:43:32.120
然后欢迎有一些问题

1248
00:43:32.200 --> 00:43:34.320
咱们随时进行交流和讨论

1249
00:43:35.040 --> 00:43:35.280
好

1250
00:43:35.800 --> 00:43:38.160
以上是我今天的分享的全部内容

1251
00:43:38.360 --> 00:43:38.840
谢谢大家

1252
00:43:46.280 --> 00:43:47.080
这个问题非常好

1253
00:43:47.320 --> 00:43:48.400
因为我们做了很多年

1254
00:43:48.440 --> 00:43:50.920
所以还是踩过了不少坑

1255
00:43:50.920 --> 00:43:52.360
跟大家分享一下

1256
00:43:53.160 --> 00:43:54.760
在刚才会上我提到了

1257
00:43:54.800 --> 00:43:57.360
说我们初期阶段要做解决先无到有

1258
00:43:57.880 --> 00:43:59.720
不知道你记不记得先无到有

1259
00:44:00.360 --> 00:44:01.360
既然先无到有

1260
00:44:01.800 --> 00:44:02.760
怎么个有法

1261
00:44:03.000 --> 00:44:03.800
还是有策略的

1262
00:44:04.800 --> 00:44:07.600
所以在这里给大家分享一个非常实用的

1263
00:44:08.120 --> 00:44:09.080
非常实用的手段

1264
00:44:09.480 --> 00:44:10.320
怎么先无到有

1265
00:44:10.360 --> 00:44:11.640
因为你先无到有

1266
00:44:11.680 --> 00:44:13.280
不是说只我有一个

1267
00:44:13.760 --> 00:44:15.120
整个日志SDK大家都来报

1268
00:44:15.560 --> 00:44:16.600
你随便往里整

1269
00:44:16.600 --> 00:44:17.160
这样

1270
00:44:17.160 --> 00:44:19.320
你日志的分类和量会非常大

1271
00:44:19.880 --> 00:44:21.200
所以这里有个非常关键的点

1272
00:44:21.240 --> 00:44:21.760
就是分类

1273
00:44:22.280 --> 00:44:22.960
怎么分类

1274
00:44:23.280 --> 00:44:24.640
就要和你整个

1275
00:44:25.080 --> 00:44:26.040
如果你是APP

1276
00:44:26.040 --> 00:44:27.440
我拿APP做举例

1277
00:44:27.440 --> 00:44:28.400
如果你是APP

1278
00:44:29.000 --> 00:44:30.720
你整个APP的架构层面

1279
00:44:31.280 --> 00:44:32.240
有哪些通用的组件

1280
00:44:33.080 --> 00:44:34.600
你跟这些通用组件合作

1281
00:44:34.800 --> 00:44:36.600
比如刚才提到说我跟存储合作

1282
00:44:37.560 --> 00:44:38.720
把存储的一些异常

1283
00:44:38.720 --> 00:44:39.760
和关键信息打上

1284
00:44:40.240 --> 00:44:41.520
我跟网络组件合作

1285
00:44:41.520 --> 00:44:43.040
我把网络的打上

1286
00:44:43.400 --> 00:44:47.160
我跟动态化容器层合作

1287
00:44:47.520 --> 00:44:48.920
然后容器的关键信息打上

1288
00:44:50.000 --> 00:44:50.360
这样

1289
00:44:50.400 --> 00:44:51.760
你就能够很快地

1290
00:44:51.800 --> 00:44:53.720
把你的日志收敛到一个

1291
00:44:54.600 --> 00:44:56.560
非常可枚举的范围内

1292
00:44:57.360 --> 00:44:59.120
这样也不会那么分散

1293
00:44:59.120 --> 00:45:00.880
而且由于做了分层

1294
00:45:01.360 --> 00:45:02.920
你去分析问题的时候

1295
00:45:02.920 --> 00:45:03.680
也更有针对性

1296
00:45:04.200 --> 00:45:04.880
这是第一点

1297
00:45:05.480 --> 00:45:07.560
第二点就是刚才提到了

1298
00:45:09.160 --> 00:45:12.120
日志我们分了层上报上面了

1299
00:45:12.120 --> 00:45:13.920
上报上面得有人用

1300
00:45:14.160 --> 00:45:14.680
谁用呢

1301
00:45:15.080 --> 00:45:16.960
绝大部分是我们的开发者去用

1302
00:45:17.520 --> 00:45:20.880
然后开发者去用我们去做的工具

1303
00:45:20.880 --> 00:45:21.960
可能就是面向开发者的

1304
00:45:22.440 --> 00:45:24.440
我们把它叫日志分析平台

1305
00:45:25.400 --> 00:45:26.240
日志分析平台

1306
00:45:26.360 --> 00:45:28.760
我们就要这里有个很关键的点

1307
00:45:29.520 --> 00:45:30.360
那就要去

1308
00:45:31.000 --> 00:45:32.680
我们就要去主动去了解用户

1309
00:45:32.720 --> 00:45:34.200
到底需要什么的场景

1310
00:45:34.720 --> 00:45:37.480
比如说我们有网络面板

1311
00:45:38.120 --> 00:45:39.440
就专门去分析网络的

1312
00:45:39.800 --> 00:45:40.560
有网络面板

1313
00:45:40.920 --> 00:45:43.160
也可能有这个叫Timeline

1314
00:45:44.040 --> 00:45:48.640
叫时间流就时间的那种分类

1315
00:45:49.160 --> 00:45:49.920
以及比如说

1316
00:45:49.920 --> 00:45:52.000
我们还做了很应用功能

1317
00:45:52.000 --> 00:45:53.080
就是能够快速的

1318
00:45:53.600 --> 00:45:57.040
去进行筛选某些类的日志

1319
00:45:57.440 --> 00:45:57.800
这样

1320
00:45:57.800 --> 00:45:58.600
你能快速地进行检索

1321
00:45:59.200 --> 00:46:02.000
所以你日志分析平台上面的这些功能

1322
00:46:04.000 --> 00:46:05.040
是非常重要的

1323
00:46:05.040 --> 00:46:06.200
而且是非常贴近

1324
00:46:07.080 --> 00:46:08.320
一线同学去使用

1325
00:46:08.360 --> 00:46:11.560
然后和业务场景强相关的

1326
00:46:11.600 --> 00:46:12.560
所以在这个领域

1327
00:46:13.480 --> 00:46:15.880
是一个非常重要的关键点

1328
00:46:16.440 --> 00:46:18.600
对第三个关键点就是

1329
00:46:19.400 --> 00:46:24.080
大家要分好监控和日志的定位

1330
00:46:24.600 --> 00:46:25.640
这俩要配合使用

1331
00:46:26.760 --> 00:46:27.960
因为你不能说我光有日志

1332
00:46:28.240 --> 00:46:28.720
没有监控

1333
00:46:28.720 --> 00:46:29.200
这样

1334
00:46:30.240 --> 00:46:31.800
你的整个服务发生什么问题

1335
00:46:31.800 --> 00:46:32.400
你都不知道

1336
00:46:33.200 --> 00:46:37.920
所以偏向于监控是发现问题

1337
00:46:37.920 --> 00:46:39.240
但是它可能不能定位

1338
00:46:39.240 --> 00:46:40.480
或者是定位一个大概

1339
00:46:41.200 --> 00:46:43.760
比如说我的网络接口成功率突然掉了

1340
00:46:44.680 --> 00:46:46.320
它只知道我网络成功率掉了

1341
00:46:46.360 --> 00:46:47.480
但是我不知道发生什么

1342
00:46:47.960 --> 00:46:49.520
日志更偏向于说

1343
00:46:49.560 --> 00:46:51.160
当发现一类的事件

1344
00:46:51.280 --> 00:46:52.720
它可能当时还称为事件

1345
00:46:53.320 --> 00:46:56.880
我通过日志真正能够解释出

1346
00:46:56.880 --> 00:46:57.760
到底发生什么事

1347
00:46:58.280 --> 00:46:59.920
所以这是这个关键

1348
00:46:59.960 --> 00:47:00.960
所以他们要配合使用

1349
00:47:01.000 --> 00:47:02.240
不是说我光有日志系统

1350
00:47:02.280 --> 00:47:04.240
我就解决了我所有的运维问题

1351
00:47:04.440 --> 00:47:05.360
这是不可能做到

1352
00:47:06.120 --> 00:47:10.120
以上就是给大家的一些关键的建议

